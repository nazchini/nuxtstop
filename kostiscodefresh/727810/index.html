<!doctype html>
<html data-n-head-ssr lang="en" data-n-head="%7B%22lang%22:%7B%22ssr%22:%22en%22%7D%7D">
  <head>
    <title>Enterprise CI/CD Best Practices – Part 3</title><meta data-n-head="ssr" charset="utf-8"><meta data-n-head="ssr" name="viewport" content="width=device-width,initial-scale=1"><meta data-n-head="ssr" data-hid="description" name="description" content="Using Nuxt.js fetch() hook to build dev.to with a new look"><meta data-n-head="ssr" name="format-detection" content="telephone=no"><base href="/nuxtstop/"><link data-n-head="ssr" rel="icon" type="image/x-icon" href="/favicon.ico"><link data-n-head="ssr" rel="stylesheet" href="https://fonts.googleapis.com/css?family=Inter:400,500,600&display=swap"><link rel="preload" href="/nuxtstop/_nuxt/f6e87fb.js" as="script"><link rel="preload" href="/nuxtstop/_nuxt/6474719.js" as="script"><link rel="preload" href="/nuxtstop/_nuxt/9b75090.js" as="script"><link rel="preload" href="/nuxtstop/_nuxt/18df600.js" as="script"><link rel="preload" href="/nuxtstop/_nuxt/dc9ce94.js" as="script"><style data-vue-ssr-id="c650fd98:0 af4684f0:0 a9c71758:0 dcafa518:0 4b9cec49:0 b093d766:0 9d98bcb4:0 6b6a11ea:0 0248ed80:0 ea8e4264:0">html{box-sizing:border-box;font-family:sans-serif;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}*,:after,:before{box-sizing:inherit}html{font-family:-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Noto Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";line-height:1.5}*,:after,:before{border:0 solid #e0e0e0}blockquote,body,dd,dl,figure,h1,h2,h3,h4,h5,h6,p,pre{margin:0}button{background:0 0;padding:0}button:focus{outline:1px dotted;outline:5px auto -webkit-focus-ring-color}fieldset,ol,ul{margin:0;padding:0}ol,ul{list-style:none}hr{border-width:1px}img{border-style:solid}textarea{resize:vertical}input::-moz-placeholder,textarea::-moz-placeholder{color:inherit;opacity:.5}input:-ms-input-placeholder,textarea:-ms-input-placeholder{color:inherit;opacity:.5}input::placeholder,textarea::placeholder{color:inherit;opacity:.5}[role=button],button{cursor:pointer}table{border-collapse:collapse}h1,h2,h3,h4,h5,h6{font-size:inherit;font-weight:inherit;font-family:sans-serif}a{color:inherit;text-decoration:inherit}button,input,optgroup,select,textarea{padding:0;line-height:inherit;color:inherit;font-family:inherit;font-size:100%}code,kbd,pre,samp{font-family:SFMono-Regular,Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace;overflow:auto;word-break:break-word;white-space:normal}audio,canvas,embed,iframe,img,object,svg,video{display:block;vertical-align:middle}img,video{max-width:100%;height:auto}html{height:100%;font-size:18px;-ms-overflow-style:scrollbar;-webkit-tap-highlight-color:transparent;-webkit-touch-callout:none}@media(min-width:640px){html{font-size:20px}}body{height:100%;min-width:320px;font-family:Inter,-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Noto Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";font-weight:400;line-height:1.5;color:#000;background-color:#eff4f7;-webkit-text-rendering:optimizeLegibility;text-rendering:optimizeLegibility;font-synthesis:none;font-kerning:normal;font-feature-settings:"normal","kern";-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;-webkit-overflow-scrolling:touch;overflow-x:hidden;overflow-y:scroll}h1,h2,h3,h4,h5,h6{color:#000;font-family:Inter,-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Noto Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";font-weight:600;font-feature-settings:"normal";line-height:1.2}pre{background:#29292e;border-radius:2px;overflow:auto;padding:1rem;color:#eff1f9;line-height:1.42em;font-size:13px}@media screen and (min-width:380px){pre{font-size:15px}}pre code{background:#29292e;color:#eff0f9;white-space:pre}div.highlight pre.highlight code{font-size:inherit;padding:0}div.inner-comment div.body div.highlight pre.highlight{background:#29292e}div.inner-comment div.body div.highlight pre.highlight code{font-size:inherit;white-space:inherit;background:inherit;color:inherit}.highlight .hll{background-color:#49483e}.highlight{background:#29292e;color:#f8f8f2}.highlight .c{color:grey}.highlight .err{text-shadow:0 0 7px #f9690e}.highlight .k{color:#f39c12}.highlight .l{color:plum}.highlight .n{color:#f8f8f2}.highlight .o{color:#f9690e}.highlight .p{color:#f8f8f2}.highlight .c1,.highlight .ch,.highlight .cm,.highlight .cp,.highlight .cpf,.highlight .cs{color:grey}.highlight .gd{color:#f9690e}.highlight .ge{font-style:italic}.highlight .gi{color:#7ed07e}.highlight .gs{font-weight:700}.highlight .gu{color:grey}.highlight .kc,.highlight .kd{color:#f39c12}.highlight .kn{color:#f9690e}.highlight .kp,.highlight .kr,.highlight .kt{color:#f39c12}.highlight .ld{color:#f2ca27}.highlight .m{color:plum}.highlight .s{color:#f2ca27}.highlight .na{color:#7ed07e}.highlight .nb{color:#f8f8f2}.highlight .nc{color:#7ed07e}.highlight .no{color:#f39c12}.highlight .nd{color:#7ed07e}.highlight .ni{color:#f8f8f2}.highlight .ne,.highlight .nf{color:#7ed07e}.highlight .nl,.highlight .nn{color:#f8f8f2}.highlight .nx{color:#7ed07e}.highlight .py{color:#f8f8f2}.highlight .nt{color:#f9690e}.highlight .nv{color:#f8f8f2}.highlight .ow{color:#f9690e}.highlight .w{color:#f8f8f2}.highlight .mb,.highlight .mf,.highlight .mh,.highlight .mi,.highlight .mo{color:plum}.highlight .dl,.highlight .s2,.highlight .sa,.highlight .sb,.highlight .sc,.highlight .sd{color:#f2ca27}.highlight .se{color:plum}.highlight .s1,.highlight .sh,.highlight .si,.highlight .sr,.highlight .ss,.highlight .sx{color:#f2ca27}.highlight .bp{color:#f8f8f2}.highlight .fm{color:#7ed07e}.highlight .vc,.highlight .vg,.highlight .vi,.highlight .vm{color:#f8f8f2}.highlight .il{color:plum}.vue-content-placeholders-heading__img,.vue-content-placeholders-heading__subtitle,.vue-content-placeholders-heading__title,.vue-content-placeholders-img,.vue-content-placeholders-text__line{background:#bfcdec!important}.vue-content-placeholders-is-animated .vue-content-placeholders-heading__img:before,.vue-content-placeholders-is-animated .vue-content-placeholders-heading__subtitle:before,.vue-content-placeholders-is-animated .vue-content-placeholders-heading__title:before,.vue-content-placeholders-is-animated .vue-content-placeholders-img:before,.vue-content-placeholders-is-animated .vue-content-placeholders-text__line:before{background:linear-gradient(90deg,transparent 0,#d3ddf9 15%,transparent 30%)!important}header[data-v-27046cca]{max-width:1280px;margin:auto;padding:1rem;height:6rem;border-bottom:1px solid rgba(0,0,0,.2)}header .logo-wrapper[data-v-27046cca],header[data-v-27046cca]{display:flex;align-items:center;justify-content:space-between}header .logo-wrapper[data-v-27046cca]{margin:0 .5rem}header .logo-wrapper svg[data-v-27046cca]{width:3rem;height:100%}header .logo-wrapper .name-wrapper[data-v-27046cca]{margin-left:.6em}header .logo-wrapper .name-wrapper .subtitle[data-v-27046cca]{font-size:1rem}header .logo-wrapper .name-wrapper .app-name[data-v-27046cca]{font-weight:700;font-size:2.25rem;line-height:1.25}header nav[data-v-27046cca]{letter-spacing:-.025rem;font-weight:600;text-transform:uppercase}header nav ul[data-v-27046cca]{display:flex}header nav ul li[data-v-27046cca]{margin:0 .5rem}header nav ul li a[data-v-27046cca]{box-shadow:-4px -4px 8px #f8fafe,4px 4px 8px #ced2db;padding:.25rem 1rem;border-radius:.5rem;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}header nav ul li a[data-v-27046cca]:hover{background:linear-gradient(135deg,rgba(0,0,0,.09),hsla(0,0%,100%,0))}header nav ul li a.nuxt-link-exact-active[data-v-27046cca]{cursor:default}header nav ul li a.nuxt-link-exact-active[data-v-27046cca],header nav ul li a[data-v-27046cca]:active{background:0 0;box-shadow:inset -4px -4px 8px #f0f3f9,inset 4px 4px 8px #ced2db,inset -1px -1px 4px #8e8e8e}.page-wrapper[data-v-10d06ee8]{max-width:1280px;margin:auto;padding:1rem}.article-content-wrapper[data-v-10d06ee8]{display:flex;flex-direction:column;align-items:center;margin:auto auto 2rem}@media(min-width:1024px){.article-content-wrapper[data-v-10d06ee8]{align-items:normal;flex-direction:row}}.article-content-wrapper .article-block[data-v-10d06ee8]{width:100%;max-width:880px}@media(min-width:1024px){.article-content-wrapper .article-block[data-v-10d06ee8]{margin-right:1rem;width:66.66666%;margin-bottom:2rem}}.article-content-wrapper .aside-username-wrapper[data-v-10d06ee8]{max-width:880px;width:100%;position:relative}@media(min-width:1024px){.article-content-wrapper .aside-username-wrapper[data-v-10d06ee8]{display:block;width:33.33333%}}.article-content-wrapper .aside-username-wrapper .aside-username-block[data-v-10d06ee8]{position:-webkit-sticky;position:sticky;top:1rem}@media(min-width:1280px){.comments-block[data-v-10d06ee8]{margin:.5rem}}article[data-v-70afb46a]{padding:.5rem;border-radius:1rem}header h1[data-v-70afb46a],header[data-v-70afb46a]{margin-bottom:1rem}header h1[data-v-70afb46a]{font-size:2.25rem;letter-spacing:-.025rem}header .tags[data-v-70afb46a]{display:flex;flex-wrap:wrap;margin-bottom:1.5rem}header .tags .tag[data-v-70afb46a]{font-weight:500;line-height:1;padding:.5rem;margin:0 .5rem .5rem 0;border-radius:.25rem;box-shadow:-4px -4px 8px #f8fafe,4px 4px 8px #ced2db}header .tags .tag[data-v-70afb46a]:hover{background:linear-gradient(135deg,rgba(0,0,0,.09),hsla(0,0%,100%,0))}header .tags .tag[data-v-70afb46a]:active{background:0 0;box-shadow:inset -4px -4px 8px #f0f3f9,inset 4px 4px 8px #ced2db,inset -1px -1px 4px #8e8e8e}header .image-wrapper[data-v-70afb46a]{position:relative;padding-bottom:56.25%;background-color:#d4dfe8;margin-bottom:1.5rem;border-radius:.5rem;overflow:hidden}@media(min-width:834px){header .image-wrapper[data-v-70afb46a]{margin-bottom:1.5rem}}header .image-wrapper img[data-v-70afb46a]{position:absolute;top:0;left:0;width:100%;height:100%;-o-object-fit:cover;object-fit:cover}header .meta[data-v-70afb46a]{line-height:1;font-size:.875rem;text-transform:uppercase;font-weight:500;letter-spacing:-.025rem;display:flex;align-items:center;justify-content:space-between}header .meta .scl[data-v-70afb46a]{display:flex}header .meta .scl span[data-v-70afb46a]{display:flex;align-items:center;margin-right:1rem}header .meta .scl span svg[data-v-70afb46a]{margin-right:.25rem}header .meta .scl .comments[data-v-70afb46a]{cursor:pointer}[data-v-70afb46a] .content .ltag__user{display:none}[data-v-70afb46a] .content iframe{max-width:100%}[data-v-70afb46a] .content h1{font-size:1.875rem}[data-v-70afb46a] .content h1,[data-v-70afb46a] .content h2{margin-top:2rem;margin-bottom:1rem;letter-spacing:-.025rem}[data-v-70afb46a] .content h2{font-size:1.5rem}[data-v-70afb46a] .content h3{font-size:1.25rem}[data-v-70afb46a] .content h3,[data-v-70afb46a] .content h4{margin-top:2rem;margin-bottom:1rem;letter-spacing:-.025rem}[data-v-70afb46a] .content h4{font-size:1rem}[data-v-70afb46a] .content a{color:#6e87d2}[data-v-70afb46a] .content p{margin-bottom:1rem;line-height:1.4}[data-v-70afb46a] .content p code{background-color:#d2f3e1;border-radius:.25rem;padding:.25rem}[data-v-70afb46a] .content img{width:100%;border-radius:.5rem}[data-v-70afb46a] .content .highlight{margin-bottom:1rem;border-radius:.5rem}[data-v-70afb46a] .content ul{list-style:numeral;margin-bottom:1rem}[data-v-70afb46a] .content ul li p{margin-bottom:0}[data-v-70afb46a] .content ol{margin-bottom:1rem}aside[data-v-37984f8c]{padding:1rem;background-color:#dfe8ef;border-radius:1rem}aside .username-heading[data-v-37984f8c]{display:flex;margin-bottom:1rem}aside .username-heading[data-v-37984f8c]:hover{color:#6e87d2}aside .username-heading img[data-v-37984f8c]{width:3rem;height:3rem;border-radius:50%;margin-right:1rem}aside .username-heading .text[data-v-37984f8c]{display:flex;flex-direction:column;justify-content:center}aside .username-heading .text a[data-v-37984f8c]{line-height:1}aside .username-heading .text a[data-v-37984f8c]:first-child{font-size:1.25rem;font-weight:500;letter-spacing:-.025rem;margin-bottom:.25rem}aside .username-heading .text a[data-v-37984f8c]:last-child{color:#999;font-size:.875rem}aside .username-heading.loading[data-v-37984f8c]{display:block}aside .f-button[data-v-37984f8c]{display:block;width:100%;padding:.5rem;border-radius:.5rem;box-shadow:-4px -4px 8px #f8fafe,4px 4px 8px #ced2db;text-transform:uppercase;text-align:center;font-weight:600;letter-spacing:-.025rem;margin-bottom:1rem}aside .f-button[data-v-37984f8c]:hover{background:linear-gradient(135deg,rgba(0,0,0,.09),hsla(0,0%,100%,0))}aside .f-button[data-v-37984f8c]:active{background:0 0;box-shadow:inset -4px -4px 8px #f0f3f9,inset 4px 4px 8px #ced2db,inset -1px -1px 4px #8e8e8e}aside .info>div[data-v-37984f8c]{margin-bottom:.5rem}aside .info .title[data-v-37984f8c]{font-size:.666666rem;letter-spacing:-.0125rem;font-weight:500;color:#999;text-transform:uppercase;margin-bottom:.1rem}aside .info .content[data-v-37984f8c]{font-size:.875rem;line-height:1.4}.add-comment[data-v-8c4375bc]{display:block;width:100%;padding:.5rem;border-radius:.5rem;box-shadow:-4px -4px 8px #f8fafe,4px 4px 8px #ced2db;text-transform:uppercase;text-align:center;font-weight:600;letter-spacing:-.025rem;margin-bottom:1rem}.add-comment[data-v-8c4375bc]:hover{background:linear-gradient(135deg,rgba(0,0,0,.09),hsla(0,0%,100%,0))}.add-comment[data-v-8c4375bc]:active{background:0 0;box-shadow:inset -4px -4px 8px #f0f3f9,inset 4px 4px 8px #ced2db,inset -1px -1px 4px #8e8e8e}footer[data-v-22cb8fd0]{padding:2rem;text-align:center;display:flex;align-items:center;justify-content:center}footer span[data-v-22cb8fd0]{display:inline-block;line-height:1;text-transform:uppercase;letter-spacing:-.025rem;font-size:.75rem;font-weight:500}footer a svg[data-v-22cb8fd0]{width:3rem;height:3rem;margin:0 .5rem}footer a .nuxt-icon[data-v-22cb8fd0]{width:2.5rem;height:2.5rem;margin:0 .25rem}</style>
  </head>
  <body>
    <div data-server-rendered="true" id="__nuxt"><div id="__layout"><div><header data-v-27046cca><a href="/nuxtstop/" class="logo-wrapper nuxt-link-active" data-v-27046cca><svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" data-v-27046cca><path d="M13.5599 8.54348L12.8055 9.87164L10.2257 5.3282L2.306 19.274H7.66815C7.66815 20.0075 8.25298 20.6021 8.97441 20.6021H2.306C1.83937 20.6021 1.40822 20.3489 1.17494 19.9379C0.941664 19.527 0.941687 19.0208 1.175 18.6099L9.09469 4.66412C9.32802 4.25316 9.75926 4 10.226 4C10.6926 4 11.1239 4.25316 11.3572 4.66412L13.5599 8.54348V8.54348Z" fill="#00C58E" data-v-27046cca></path><path d="M19.2769 18.6099L14.3143 9.87165L13.5599 8.54348L12.8055 9.87165L7.84343 18.6099C7.61011 19.0208 7.61009 19.527 7.84337 19.9379C8.07665 20.3489 8.50779 20.6021 8.97443 20.6021H18.1443C18.611 20.6021 19.0424 20.3491 19.2758 19.9382C19.5092 19.5272 19.5092 19.0209 19.2758 18.6099H19.2769ZM8.97443 19.274L13.5599 11.1998L18.1443 19.274H8.97443H8.97443Z" fill="#2F495E" data-v-27046cca></path><path d="M22.825 19.938C22.5917 20.3489 22.1606 20.6021 21.694 20.6021H18.1443C18.8657 20.6021 19.4505 20.0075 19.4505 19.274H21.6913L15.3331 8.07696L14.3142 9.87164L13.5599 8.54348L14.2021 7.41287C14.4354 7.00192 14.8667 6.74875 15.3334 6.74875C15.8001 6.74875 16.2313 7.00192 16.4646 7.41287L22.825 18.6099C23.0583 19.0208 23.0583 19.5271 22.825 19.938V19.938Z" fill="#108775" data-v-27046cca></path></svg> <div class="name-wrapper" data-v-27046cca><span class="app-name" data-v-27046cca>Nuxtstop</span> <p class="subtitle" data-v-27046cca>For all things nuxt.js</p></div></a> <nav data-v-27046cca><ul data-v-27046cca><li data-v-27046cca><a href="/nuxtstop/" class="nuxt-link-active" data-v-27046cca>
          New
        </a></li><li data-v-27046cca><a href="/nuxtstop/top" data-v-27046cca>
          Top
        </a></li></ul></nav></header> <div class="page-wrapper" data-v-10d06ee8><div class="article-content-wrapper" data-v-10d06ee8><article data-fetch-key="data-v-70afb46a:0" class="article-block" data-v-70afb46a data-v-10d06ee8><header data-v-70afb46a><h1 data-v-70afb46a>Enterprise CI/CD Best Practices – Part 3</h1> <div class="tags" data-v-70afb46a><a href="/nuxtstop/t/cloud" class="tag" data-v-70afb46a>
          #cloud
        </a><a href="/nuxtstop/t/devops" class="tag" data-v-70afb46a>
          #devops
        </a><a href="/nuxtstop/t/ci" class="tag" data-v-70afb46a>
          #ci
        </a><a href="/nuxtstop/t/cd" class="tag" data-v-70afb46a>
          #cd
        </a></div> <div class="image-wrapper" data-v-70afb46a><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--XzA6MDv---/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/p0rrvptajt3nbl71hrde.jpg" alt="Enterprise CI/CD Best Practices – Part 3" data-v-70afb46a></div> <div class="meta" data-v-70afb46a><div class="scl" data-v-70afb46a><span data-v-70afb46a><svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" data-v-70afb46a data-v-70afb46a><path d="M16.4444 3C14.6733 3 13.0333 3.94162 12 5.34C10.9667 3.94162 9.32667 3 7.55556 3C4.49222 3 2 5.52338 2 8.625C2 14.8024 11.0267 20.586 11.4122 20.829C11.5922 20.9426 11.7956 21 12 21C12.2044 21 12.4078 20.9426 12.5878 20.829C12.9733 20.586 22 14.8024 22 8.625C22 5.52338 19.5078 3 16.4444 3Z" fill="#FF0000" data-v-70afb46a data-v-70afb46a></path></svg>
            3
          </span> <span class="comments" data-v-70afb46a><svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" data-v-70afb46a data-v-70afb46a><path d="M6.11765 22H4.94118L5.64706 21.05C6.11765 20.3969 6.41176 19.5656 6.58824 18.5563C3.64706 17.1906 2 14.6375 2 11.3125C2 6.20625 5.82353 3 12 3C18.1765 3 22 6.20625 22 11.3125C22 16.5375 18.2353 19.625 12 19.625H11.5882C10.6471 20.7531 9 22 6.11765 22ZM12 4.1875C6.47059 4.1875 3.17647 6.85937 3.17647 11.3125C3.17647 15.1125 5.47059 16.8938 7.41177 17.6656L7.82353 17.8437L7.76471 18.3187C7.64706 19.2687 7.47059 20.1 7.11765 20.8125C9.05882 20.575 10.1765 19.5656 10.8235 18.7344L11 18.4969H12C19.9412 18.4969 20.8235 13.5094 20.8235 11.3719C20.8235 6.85938 17.5294 4.1875 12 4.1875Z" fill="black" data-v-70afb46a data-v-70afb46a></path></svg>
            0
          </span></div> <time data-v-70afb46a>Jun 14 '21</time></div></header> <div class="content" data-v-70afb46a><p>This is the third and last part in our “Enterprise CI/CD best practices” series. See also <a href="https://dev.to/codefreshio/enterprise-ci-cd-best-practices-part-1-2n5m">part 1</a> and <a href="https://dev.to/codefreshio/enterprise-ci-cd-best-practices-part-2-3o24">part 2</a> for the previous best practices.</p>

<h2>
  <a name="best-practice-16-database-updates-have-their-own-lifecycle" href="#best-practice-16-database-updates-have-their-own-lifecycle">
  </a>
  Best Practice 16 – Database Updates have their own Lifecycle
</h2>

<p>As more and more companies adopt continuous delivery we see an alarming trend of treating databases as an external entity that exists outside of the delivery process. This could not be further from the truth.</p>

<p>Databases (and other supporting systems such as message queues, caches, service discovery solutions, etc.) should be handled like any other software project. This means:</p>

<ol>
<li>Their configuration and contents should be stored in version control</li>
<li>All associated scripts, maintenance actions, and upgrade/downgrade instructions should also be in version control</li>
<li>Configuration changes should be approved like any other software change (passing from automated analysis, pull request review, security scanning, unit testing, etc.)</li>
<li>Dedicated pipelines should be responsible for installing/upgrading/rolling back each new version of the database</li>
</ol>

<p>The last point is especially important. There are a lot of programming frameworks (e.g., rails migrations, Java Liquibase, ORM migrations) that allow the application itself to handle DB migrations. Usually the first time the application startup it can also upgrade the associate database to the correct schema. While convenient, this practice makes rollbacks very difficult and is best avoided.</p>

<p>Database migration should be handled like an isolated software upgrade. You should have automated pipelines that deal only with the database, and the application pipelines should not touch the database in any way. This will give you the maximum flexibility to handle database upgrades and rollbacks by controlling exactly when and how a database upgrade takes place.</p>

<h2>
  <a name="best-practice-17-database-updates-are-automated" href="#best-practice-17-database-updates-are-automated">
  </a>
  Best Practice 17 – Database Updates are Automated
</h2>

<p>Several organizations have stellar pipelines for the application code, but pay very little attention to automation for database updates. Handling databases should be given the same importance (if not more) as with the application itself.</p>

<p>This means that you should similarly automate databases to application code:</p>

<ul>
<li>Store database changesets in source control</li>
<li>Create pipelines that automatically update your database when a new changeset is created</li>
<li>Have dynamic temporary environments for databases where changesets are reviewed before being merged to mainly</li>
<li>Have code reviews and other quality checks on database changesets</li>
<li>Have a strategy for doing rollbacks after a failed database upgrade</li>
</ul>

<p>It also helps if you automate the transformation of production data to test data that can be used in your test environments for your application code. In most cases, it is inefficient (or even impossible due to security constraints) to keep a copy of all production data in test environments. It is better to have a small subset of data that is anonymized/simplified so that it can be handled more efficiently.</p>

<h2>
  <a name="best-practice-18-perform-gradual-database-upgrades" href="#best-practice-18-perform-gradual-database-upgrades">
  </a>
  Best Practice 18 – Perform Gradual Database Upgrades
</h2>

<p>Application rollbacks are well understood and we are now at the point where we have dedicated tools that perform rollbacks after a failed application deployment. And with progressively delivery techniques such as canaries and blue/green deployments, we can minimize the downtime even further.</p>

<p>Progressive delivery techniques do not work on databases (because of the inherent state), but we can plan the database upgrades and adopt <a href="https://martinfowler.com/articles/evodb.html">evolutionary database design principles</a>.</p>

<p>By following an evolutionary design you can make all your database changesets backward and forwards compatible allowing you to rollback application and database changes at any time without any ill effects</p>

<p>As an example, if you want to rename a column, instead of simply creating a changeset the renames the column and performing a single database upgrade, you instead follow a schedule of gradual updates as below:</p>

<p>Database changeset that only adds a new column with the new name (and copies existing data from the old column). The application code is still writing/reading from the old column<br>
Application upgrade where the application code now writes to both columns but reads from the new column<br>
Application upgrade where the application code writes/reads only to the new column<br>
Database upgrade that removes the old column</p>

<p>The process needs a well-disciplined team as it makes each database change span over several deployments. But the advantages of this process cannot be overstated. At any stage in this process, you can go back to the previous version without losing data and without the need for downtime.</p>

<p>For the full list of techniques see the <a href="https://databaserefactoring.com/">database refactoring website</a>.</p>

<h2>
  <a name="best-practice-19-all-deployments-must-happen-via-the-cd-platform-only-and-never-from-workstations" href="#best-practice-19-all-deployments-must-happen-via-the-cd-platform-only-and-never-from-workstations">
  </a>
  Best Practice 19 – All deployments must happen via the CD platform only (and never from workstations)
</h2>

<p>Continuing the theme of immutable artifacts and deployments that send to production what was deployed, we must also make sure the pipelines themselves are the only single path to production.</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--FRwut5zv--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/1v9y4k6ky6jqf3nkk8fe.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--FRwut5zv--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/1v9y4k6ky6jqf3nkk8fe.png" alt="Single way to deploy" loading="lazy"></a></p>

<p>The main way to use CI/CD pipelines as intended is to make sure that the CI/CD platform is the <strong>only</strong> application that can deploy to production. This practice guarantees that production environments are running what they are expected to be running (i.e., the last artifact that was deployed).</p>

<p>Unfortunately, several organizations either allow developers to deploy directly from their workstations, or even to “inject” their artifacts in a pipeline at various stages.</p>

<p>This is a very dangerous practice as it breaks the traceability and monitoring offered by a proper CI/CD platform. It allows developers to deploy to production features that might not be committed in source control in the first place. A lot of failed deployments stem from a missing file that was present on a developer workstation and not in source control.</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--rmHU_ajC--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/qm05nmk1eukrv5w74r4d.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--rmHU_ajC--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/qm05nmk1eukrv5w74r4d.png" alt="Multiple ways to deploy" loading="lazy"></a></p>

<p>In summary, there is only a single critical path for deployments, and this path is strictly handed by the CI/CD platform. Deploying production code from developer workstations should be prohibited at the network/access/hardware level.</p>

<h2>
  <a name="best-practice-20-use-progressive-deployment-patterns" href="#best-practice-20-use-progressive-deployment-patterns">
  </a>
  Best Practice 20 – Use Progressive Deployment Patterns
</h2>

<p>We already talked about database deployments in best practice 18 and how each database upgrade should be forwards and backward compatible. This pattern goes hand-in-hand with progressive delivery patterns on the application side.</p>

<p>Traditional deployments follow an all-or-nothing approach where all application instances move forward to the next version of the software. This is a very simple deployment approach but makes rollbacks a challenging process.</p>

<p>You should instead look at:</p>

<ol>
<li>
<a href="https://martinfowler.com/bliki/BlueGreenDeployment.html">Blue/Green deployments</a> that deploy a whole new set of instances of the new version, but still keep the old one for easy rollbacks</li>
<li>
<a href="https://martinfowler.com/bliki/CanaryRelease.html">Canary releases</a> where only a subset of the application instances move to the new version. Most users are still routed to the previous version</li>
</ol>

<p>If you couple these techniques with gradual database deployments, you can minimize the amount of downtime involved when a new deployment happens. Rollbacks also become a trivial process as in both cases you simply change your load balancer/service mesh to the previous configuration and all users are routed back to the original version of the application.</p>

<p>Make sure to also look at involving your metrics (see best practices 21 and 22) in the deployment process for fully automated rollbacks.</p>

<h2>
  <a name="best-practice-21-metrics-and-logs-can-detect-a-bad-deployment" href="#best-practice-21-metrics-and-logs-can-detect-a-bad-deployment">
  </a>
  Best Practice 21 – Metrics and logs can detect a bad deployment
</h2>

<p>Having a pipeline that deploys your application (even when you use progressive delivery) is not enough if you want to know what is the real result of the deployment. Deployments that look “successful” at first glance, but soon prove to introduce regressions is a very common occurrence in large software projects.</p>

<p>A lot of development teams simply perform a visual check/smoke test after a deployment has finished and call it a day if everything “looks” good. But this practice is not enough and can quickly lead to the introduction of subtle bugs or performance issues.</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--Mf4QGAqw--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/or6337bmbdgfj4228ohk.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--Mf4QGAqw--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/or6337bmbdgfj4228ohk.png" alt="Without metrics" loading="lazy"></a></p>

<p>The correct approach is the adoption of application (and infrastructure) metrics. This includes:</p>

<ul>
<li>Detailed logs for application events</li>
<li>Metrics that count and monitor key features of the application</li>
<li>Tracing information that can provide an in-depth understanding of what a single request is doing</li>
</ul>

<p>Once these metrics are in place, the effects of deployment should be judged according to a before/after comparison of these metrics. This means that metrics should not be simply a debugging mechanism (post-incident), but should act instead as an early warning measure against failed deployments.</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--GDbWxTpC--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/7korybc2m6olc4xb5szl.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--GDbWxTpC--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/7korybc2m6olc4xb5szl.png" alt="With metrics" loading="lazy"></a></p>

<p>Choosing what events to monitor and where to place logs is a complex process. For large applications, it is best to follow a gradual redefinition of key metrics according to past deployments. The suggested workflow is the following:</p>

<ol>
<li>Place logs and metrics on events that you guess will show a failed deployment</li>
<li>Perform several deployments and see if your metrics can detect the failed ones</li>
<li>If you see a failed deployment that wasn’t detected in your metrics, it means that they are not enough. Fine-tune your metrics accordingly so that the next time a deployment fails in the same manner you actually know it in advance</li>
</ol>

<p>Too many times, development teams focus on “vanity” metrics, i.e., metrics that look good on paper but say nothing about a failed deployment.</p>

<h2>
  <a name="best-practice-22-automatic-rollbacks-are-in-place" href="#best-practice-22-automatic-rollbacks-are-in-place">
  </a>
  Best Practice 22 – Automatic Rollbacks are in place
</h2>

<p>This is a continuation of the previous best practice. If you already have good metrics in place (that can verify the success of a deployment) you can take them to the next level by having automated rollbacks that depend on them.</p>

<p>A lot of organizations have great metrics in place, but only manually use them:</p>

<ol>
<li>A developer looks at some key metrics before deployment</li>
<li>Deployment is triggered</li>
<li>The developer looks at the metrics in an ad-hoc manner to see what happened with the deployment</li>
</ol>

<p>While this technique is very popular, it is far from effective. Depending on the complexity of the application, the time spent watching metrics can be 1-2 hours so that the effects of the deployment have time to become visible.</p>

<p>It is not uncommon for deployments to be marked as “failed” after 6-24 hours either because nobody paid attention to the correct metrics or because people simply disregarded warnings and errors thinking that was not a result of the deployment.</p>

<p>Several organizations are also forced to only deploy during working hours because only at that time there are enough human eyes to look at metrics.</p>

<p>Metrics should become part of the deployment process. The deployment pipeline should automatically consult metrics after a deployment happens and compare them against a known threshold or their previous state. And then in a fully automated manner, the deployment should either be marked as finished or even rolled back.</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--3qDOZH9X--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/sft5m7thoznydoupmjjy.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--3qDOZH9X--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/sft5m7thoznydoupmjjy.png" alt="Automated rollbacks" loading="lazy"></a></p>

<p>This is the holy grail of deployments as it completely removes the human factor out of the equation and is a step towards Continuous Deployment (instead of Continuous Delivery). With this approach:</p>

<ol>
<li>You can perform deployments at any point in time knowing that metrics will be examined with the same attention even if the time is 3 am</li>
<li>You can catch early regressions with pinpoint accuracy</li>
<li>Rollbacks (usually a stressful action) are now handled by the deployment platform giving easier access to the deployment process by non-technical people</li>
</ol>

<p>The result is that a developer can deploy at 5 pm on Friday and immediately go home. Either the change will be approved (and it will be still there on Monday) or it will be rolled back automatically without any ill effects (and without any downtime if you also follow best practice 20 for progressive delivery)</p>

<h2>
  <a name="best-practice-23-staging-matches-production" href="#best-practice-23-staging-matches-production">
  </a>
  Best Practice 23 – Staging Matches Production
</h2>

<p>We explained in best practice 12 that you should employ dynamic environments for testing individual features for developers. This gives you the confidence that each feature is correct on its own before you deploy it in production.</p>

<p>It is also customary to have a single staging environment (a.k.a. pre-production) that acts as the last gateway before production. This particular environment should be as close to production as possible so that any configuration errors can and mismatches can be quickly discovered before pushing the application deployment to the real production environment.</p>

<p>Unfortunately, most organizations treat the staging environment in a different way than the production one. Having a staging environment that is separate from production is a cumbersome practice as it means that you have to manually maintain it and make sure that it also gets any updates that reach production (not only in application terms but also any configuration changes).</p>

<p>Two more effective ways of using a staging environment are the following:</p>

<ol>
<li>Create a staging environment on-demand each time you deploy by cloning the production environment</li>
<li>Use as staging a special part of production (sometimes called shadow production)</li>
</ol>

<p>The first approach is great for small/medium applications and involves cloning the production environment right before a deployment happens in a similar (but possibly smaller) configuration. This means that you can also get a subset of the database and a lower number of replicas/instances that serve traffic. The important point here is that this staging environment only exists during a release. You create it just before a release and destroy it once a release has been marked as “successful”.</p>

<p>The main benefit of course is that cloning your production right before deployment guarantees that you have the same configuration between staging and production. Also, there is nothing to maintain or keep up-to-date because you always discard the staging environment once the deployment has finished.</p>

<p>This approach however is not realistic for large applications with many microservices or large external resources (e.g., databases and message queues). In those cases, it is much easier to use staging as a part of the production. The important point here is that the segment of production that you use does NOT get any user traffic, so in case of a failed deployment, your users will not be affected. The advantage again is that since this is part of the production you have the same guarantee that the configuration is the most recent one and what you are testing will behave in the same way as “real” production.</p>

<h2>
  <a name="applying-these-best-practices-to-your-organization" href="#applying-these-best-practices-to-your-organization">
  </a>
  Applying these Best Practices to Your Organization
</h2>

<p>We hope that now you have some ideas on how to improve your CI/CD process. Remember however that it is better to take gradual steps and not try to change everything at once.</p>

<p>Consult the first section of this guide where we talked about priorities. Focus first on the best practices that are marked as “critical” and as soon as you have conquered them move to those with “high” importance.</p>

<p>We believe that if you adopt the majority of practices that we have described in this guide, your development teams will be able to focus on shipping features instead of dealing with failed deployments and missing configuration issues.</p>

<p>Cover photo by <a href="https://unsplash.com/photos/jHZ70nRk7Ns">Unsplash</a>.</p>

</div></article> <div class="aside-username-wrapper" data-v-10d06ee8><aside class="aside-username-block" data-v-37984f8c data-v-10d06ee8><div class="username-heading loading" data-v-37984f8c><div class="vue-content-placeholders vue-content-placeholders-is-animated" data-v-37984f8c><div class="vue-content-placeholders-heading" data-v-37984f8c><div class="vue-content-placeholders-heading__img"></div> <div class="vue-content-placeholders-heading__content"><div class="vue-content-placeholders-heading__title"></div> <div class="vue-content-placeholders-heading__subtitle"></div></div></div></div></div> <div class="info" data-v-37984f8c><div class="vue-content-placeholders vue-content-placeholders-is-animated" data-v-37984f8c><div class="vue-content-placeholders-text" data-v-37984f8c><div class="vue-content-placeholders-text__line"></div><div class="vue-content-placeholders-text__line"></div><div class="vue-content-placeholders-text__line"></div></div></div></div></aside></div></div> <div class="comments-block" data-v-8c4375bc data-v-10d06ee8><!----> <a href="https://dev.to/kostiscodefresh/enterprise-ci-cd-best-practices-part-3-fk9" target="_blank" rel="nofollow noopener noreferer" class="add-comment" data-v-8c4375bc>
    Add comment
  </a></div></div> <footer data-v-22cb8fd0><span data-v-22cb8fd0>Built with</span> <a href="https://nuxtjs.org" target="_blank" data-v-22cb8fd0><svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" class="nuxt-icon" data-v-22cb8fd0 data-v-22cb8fd0><path d="M13.5599 8.54348L12.8055 9.87164L10.2257 5.3282L2.306 19.274H7.66815C7.66815 20.0075 8.25298 20.6021 8.97441 20.6021H2.306C1.83937 20.6021 1.40822 20.3489 1.17494 19.9379C0.941664 19.527 0.941687 19.0208 1.175 18.6099L9.09469 4.66412C9.32802 4.25316 9.75926 4 10.226 4C10.6926 4 11.1239 4.25316 11.3572 4.66412L13.5599 8.54348V8.54348Z" fill="#00C58E" data-v-22cb8fd0 data-v-22cb8fd0></path><path d="M19.2769 18.6099L14.3143 9.87165L13.5599 8.54348L12.8055 9.87165L7.84343 18.6099C7.61011 19.0208 7.61009 19.527 7.84337 19.9379C8.07665 20.3489 8.50779 20.6021 8.97443 20.6021H18.1443C18.611 20.6021 19.0424 20.3491 19.2758 19.9382C19.5092 19.5272 19.5092 19.0209 19.2758 18.6099H19.2769ZM8.97443 19.274L13.5599 11.1998L18.1443 19.274H8.97443H8.97443Z" fill="#2F495E" data-v-22cb8fd0 data-v-22cb8fd0></path><path d="M22.825 19.938C22.5917 20.3489 22.1606 20.6021 21.694 20.6021H18.1443C18.8657 20.6021 19.4505 20.0075 19.4505 19.274H21.6913L15.3331 8.07696L14.3142 9.87164L13.5599 8.54348L14.2021 7.41287C14.4354 7.00192 14.8667 6.74875 15.3334 6.74875C15.8001 6.74875 16.2313 7.00192 16.4646 7.41287L22.825 18.6099C23.0583 19.0208 23.0583 19.5271 22.825 19.938V19.938Z" fill="#108775" data-v-22cb8fd0 data-v-22cb8fd0></path></svg></a> <span data-v-22cb8fd0>&</span> <a href="https://docs.dev.to/api" rel="nofollow noopener" target="_blank" data-v-22cb8fd0><svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" data-v-22cb8fd0 data-v-22cb8fd0><path d="M1.5726 5.13748C1.42945 5.20622 1.2411 5.36661 1.15822 5.48117C1 5.69503 1 5.74849 1 11.8739C1 17.9993 1 18.0528 1.15822 18.2667C1.2411 18.3812 1.42945 18.5416 1.5726 18.6104C1.8137 18.7402 2.46164 18.7478 12 18.7478C21.5384 18.7478 22.1863 18.7402 22.4274 18.6104C22.5706 18.5416 22.7589 18.3812 22.8418 18.2667C23 18.0528 23 17.9993 23 11.8739C23 5.74849 23 5.69503 22.8418 5.48117C22.7589 5.36661 22.5706 5.20622 22.4274 5.13748C22.1863 5.00764 21.5384 5 12 5C2.46164 5 1.8137 5.00764 1.5726 5.13748ZM7.7055 8.2613C8.0822 8.45989 8.59454 9.0098 8.77536 9.40694C8.89589 9.66664 8.91095 9.94922 8.91095 12.0649C8.91095 14.3104 8.90344 14.4478 8.75275 14.7839C8.51919 15.288 8.16506 15.6546 7.68288 15.899C7.26096 16.1052 7.22328 16.1128 5.7315 16.1358L4.20206 16.1663V12.1031V8.04744L5.80684 8.07035C7.27602 8.09327 7.42672 8.10854 7.7055 8.2613ZM13.6952 8.89521V9.73538H12.4521H11.2089V10.4991V11.2629H11.9623H12.7158V12.1031V12.9432H11.9623H11.2089V13.707V14.4708H12.4521H13.6952V15.3109V16.151H12C10.1315 16.151 10.0411 16.1358 9.67191 15.6928L9.47603 15.4484V12.1336C9.47603 8.46752 9.46851 8.49807 9.95069 8.20783C10.1692 8.07035 10.3425 8.05508 11.9473 8.05508H13.6952V8.89521ZM16.5658 10.3769C16.8897 11.6295 17.1685 12.6912 17.176 12.7293C17.1911 12.7675 17.4699 11.7441 17.8014 10.461C18.1254 9.17017 18.4343 8.1009 18.4795 8.08563C18.5247 8.06271 18.9541 8.06271 19.4288 8.07035L20.3028 8.09327L19.376 11.6219C18.8713 13.5542 18.4117 15.2269 18.3664 15.3261C18.0123 16.0135 17.274 16.3343 16.7164 16.0441C16.4528 15.899 16.0911 15.4865 15.9705 15.1887C15.9254 15.0665 15.4884 13.4549 15.0062 11.6142C14.524 9.76593 14.1171 8.20783 14.0945 8.15437C14.0644 8.07035 14.2301 8.05508 15.0212 8.07035L15.9856 8.09327L16.5658 10.3769Z" fill="black" data-v-22cb8fd0 data-v-22cb8fd0></path><path d="M5.93491 12.103V14.4707H6.27394C6.66574 14.4707 7.01983 14.3103 7.1404 14.0965C7.18559 14.0048 7.21575 13.2105 7.21575 12.0648V10.1783L6.99725 9.95683C6.80133 9.76591 6.71847 9.73535 6.35683 9.73535H5.93491V12.103Z" fill="black" data-v-22cb8fd0 data-v-22cb8fd0></path></svg></a></footer></div></div></div><script>window.__NUXT__=function(e,t,a,o){return a.type_of="article",a.id=727810,a.title="Enterprise CI/CD Best Practices – Part 3",a.description="This is the third and last part in our “Enterprise CI/CD best practices” series. See also part 1 and...",a.readable_publish_date="Jun 14 '21",a.slug="enterprise-ci-cd-best-practices-part-3-fk9",a.path="/codefreshio/enterprise-ci-cd-best-practices-part-3-fk9",a.url="https://dev.to/codefreshio/enterprise-ci-cd-best-practices-part-3-fk9",a.comments_count=0,a.public_reactions_count=3,a.collection_id=13231,a.published_timestamp=t,a.positive_reactions_count=3,a.cover_image="https://res.cloudinary.com/practicaldev/image/fetch/s--XzA6MDv---/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/p0rrvptajt3nbl71hrde.jpg",a.social_image="https://res.cloudinary.com/practicaldev/image/fetch/s--4WslyjXf--/c_imagga_scale,f_auto,fl_progressive,h_500,q_auto,w_1000/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/p0rrvptajt3nbl71hrde.jpg",a.canonical_url="https://codefresh.io/devops/enterprise-ci-cd-best-practices-part-3/",a.created_at="2021-06-14T10:28:47Z",a.edited_at="2021-06-14T10:53:20Z",a.crossposted_at=e,a.published_at=t,a.last_comment_at=t,a.reading_time_minutes=10,a.tag_list="cloud, devops, ci, cd",a.tags=["cloud","devops","ci","cd"],a.body_html='<p>This is the third and last part in our “Enterprise CI/CD best practices” series. See also <a href="https://dev.to/codefreshio/enterprise-ci-cd-best-practices-part-1-2n5m">part 1</a> and <a href="https://dev.to/codefreshio/enterprise-ci-cd-best-practices-part-2-3o24">part 2</a> for the previous best practices.</p>\n\n<h2>\n  <a name="best-practice-16-database-updates-have-their-own-lifecycle" href="#best-practice-16-database-updates-have-their-own-lifecycle">\n  </a>\n  Best Practice 16 – Database Updates have their own Lifecycle\n</h2>\n\n<p>As more and more companies adopt continuous delivery we see an alarming trend of treating databases as an external entity that exists outside of the delivery process. This could not be further from the truth.</p>\n\n<p>Databases (and other supporting systems such as message queues, caches, service discovery solutions, etc.) should be handled like any other software project. This means:</p>\n\n<ol>\n<li>Their configuration and contents should be stored in version control</li>\n<li>All associated scripts, maintenance actions, and upgrade/downgrade instructions should also be in version control</li>\n<li>Configuration changes should be approved like any other software change (passing from automated analysis, pull request review, security scanning, unit testing, etc.)</li>\n<li>Dedicated pipelines should be responsible for installing/upgrading/rolling back each new version of the database</li>\n</ol>\n\n<p>The last point is especially important. There are a lot of programming frameworks (e.g., rails migrations, Java Liquibase, ORM migrations) that allow the application itself to handle DB migrations. Usually the first time the application startup it can also upgrade the associate database to the correct schema. While convenient, this practice makes rollbacks very difficult and is best avoided.</p>\n\n<p>Database migration should be handled like an isolated software upgrade. You should have automated pipelines that deal only with the database, and the application pipelines should not touch the database in any way. This will give you the maximum flexibility to handle database upgrades and rollbacks by controlling exactly when and how a database upgrade takes place.</p>\n\n<h2>\n  <a name="best-practice-17-database-updates-are-automated" href="#best-practice-17-database-updates-are-automated">\n  </a>\n  Best Practice 17 – Database Updates are Automated\n</h2>\n\n<p>Several organizations have stellar pipelines for the application code, but pay very little attention to automation for database updates. Handling databases should be given the same importance (if not more) as with the application itself.</p>\n\n<p>This means that you should similarly automate databases to application code:</p>\n\n<ul>\n<li>Store database changesets in source control</li>\n<li>Create pipelines that automatically update your database when a new changeset is created</li>\n<li>Have dynamic temporary environments for databases where changesets are reviewed before being merged to mainly</li>\n<li>Have code reviews and other quality checks on database changesets</li>\n<li>Have a strategy for doing rollbacks after a failed database upgrade</li>\n</ul>\n\n<p>It also helps if you automate the transformation of production data to test data that can be used in your test environments for your application code. In most cases, it is inefficient (or even impossible due to security constraints) to keep a copy of all production data in test environments. It is better to have a small subset of data that is anonymized/simplified so that it can be handled more efficiently.</p>\n\n<h2>\n  <a name="best-practice-18-perform-gradual-database-upgrades" href="#best-practice-18-perform-gradual-database-upgrades">\n  </a>\n  Best Practice 18 – Perform Gradual Database Upgrades\n</h2>\n\n<p>Application rollbacks are well understood and we are now at the point where we have dedicated tools that perform rollbacks after a failed application deployment. And with progressively delivery techniques such as canaries and blue/green deployments, we can minimize the downtime even further.</p>\n\n<p>Progressive delivery techniques do not work on databases (because of the inherent state), but we can plan the database upgrades and adopt <a href="https://martinfowler.com/articles/evodb.html">evolutionary database design principles</a>.</p>\n\n<p>By following an evolutionary design you can make all your database changesets backward and forwards compatible allowing you to rollback application and database changes at any time without any ill effects</p>\n\n<p>As an example, if you want to rename a column, instead of simply creating a changeset the renames the column and performing a single database upgrade, you instead follow a schedule of gradual updates as below:</p>\n\n<p>Database changeset that only adds a new column with the new name (and copies existing data from the old column). The application code is still writing/reading from the old column<br>\nApplication upgrade where the application code now writes to both columns but reads from the new column<br>\nApplication upgrade where the application code writes/reads only to the new column<br>\nDatabase upgrade that removes the old column</p>\n\n<p>The process needs a well-disciplined team as it makes each database change span over several deployments. But the advantages of this process cannot be overstated. At any stage in this process, you can go back to the previous version without losing data and without the need for downtime.</p>\n\n<p>For the full list of techniques see the <a href="https://databaserefactoring.com/">database refactoring website</a>.</p>\n\n<h2>\n  <a name="best-practice-19-all-deployments-must-happen-via-the-cd-platform-only-and-never-from-workstations" href="#best-practice-19-all-deployments-must-happen-via-the-cd-platform-only-and-never-from-workstations">\n  </a>\n  Best Practice 19 – All deployments must happen via the CD platform only (and never from workstations)\n</h2>\n\n<p>Continuing the theme of immutable artifacts and deployments that send to production what was deployed, we must also make sure the pipelines themselves are the only single path to production.</p>\n\n<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--FRwut5zv--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/1v9y4k6ky6jqf3nkk8fe.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--FRwut5zv--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/1v9y4k6ky6jqf3nkk8fe.png" alt="Single way to deploy" loading="lazy"></a></p>\n\n<p>The main way to use CI/CD pipelines as intended is to make sure that the CI/CD platform is the <strong>only</strong> application that can deploy to production. This practice guarantees that production environments are running what they are expected to be running (i.e., the last artifact that was deployed).</p>\n\n<p>Unfortunately, several organizations either allow developers to deploy directly from their workstations, or even to “inject” their artifacts in a pipeline at various stages.</p>\n\n<p>This is a very dangerous practice as it breaks the traceability and monitoring offered by a proper CI/CD platform. It allows developers to deploy to production features that might not be committed in source control in the first place. A lot of failed deployments stem from a missing file that was present on a developer workstation and not in source control.</p>\n\n<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--rmHU_ajC--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/qm05nmk1eukrv5w74r4d.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--rmHU_ajC--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/qm05nmk1eukrv5w74r4d.png" alt="Multiple ways to deploy" loading="lazy"></a></p>\n\n<p>In summary, there is only a single critical path for deployments, and this path is strictly handed by the CI/CD platform. Deploying production code from developer workstations should be prohibited at the network/access/hardware level.</p>\n\n<h2>\n  <a name="best-practice-20-use-progressive-deployment-patterns" href="#best-practice-20-use-progressive-deployment-patterns">\n  </a>\n  Best Practice 20 – Use Progressive Deployment Patterns\n</h2>\n\n<p>We already talked about database deployments in best practice 18 and how each database upgrade should be forwards and backward compatible. This pattern goes hand-in-hand with progressive delivery patterns on the application side.</p>\n\n<p>Traditional deployments follow an all-or-nothing approach where all application instances move forward to the next version of the software. This is a very simple deployment approach but makes rollbacks a challenging process.</p>\n\n<p>You should instead look at:</p>\n\n<ol>\n<li>\n<a href="https://martinfowler.com/bliki/BlueGreenDeployment.html">Blue/Green deployments</a> that deploy a whole new set of instances of the new version, but still keep the old one for easy rollbacks</li>\n<li>\n<a href="https://martinfowler.com/bliki/CanaryRelease.html">Canary releases</a> where only a subset of the application instances move to the new version. Most users are still routed to the previous version</li>\n</ol>\n\n<p>If you couple these techniques with gradual database deployments, you can minimize the amount of downtime involved when a new deployment happens. Rollbacks also become a trivial process as in both cases you simply change your load balancer/service mesh to the previous configuration and all users are routed back to the original version of the application.</p>\n\n<p>Make sure to also look at involving your metrics (see best practices 21 and 22) in the deployment process for fully automated rollbacks.</p>\n\n<h2>\n  <a name="best-practice-21-metrics-and-logs-can-detect-a-bad-deployment" href="#best-practice-21-metrics-and-logs-can-detect-a-bad-deployment">\n  </a>\n  Best Practice 21 – Metrics and logs can detect a bad deployment\n</h2>\n\n<p>Having a pipeline that deploys your application (even when you use progressive delivery) is not enough if you want to know what is the real result of the deployment. Deployments that look “successful” at first glance, but soon prove to introduce regressions is a very common occurrence in large software projects.</p>\n\n<p>A lot of development teams simply perform a visual check/smoke test after a deployment has finished and call it a day if everything “looks” good. But this practice is not enough and can quickly lead to the introduction of subtle bugs or performance issues.</p>\n\n<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--Mf4QGAqw--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/or6337bmbdgfj4228ohk.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--Mf4QGAqw--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/or6337bmbdgfj4228ohk.png" alt="Without metrics" loading="lazy"></a></p>\n\n<p>The correct approach is the adoption of application (and infrastructure) metrics. This includes:</p>\n\n<ul>\n<li>Detailed logs for application events</li>\n<li>Metrics that count and monitor key features of the application</li>\n<li>Tracing information that can provide an in-depth understanding of what a single request is doing</li>\n</ul>\n\n<p>Once these metrics are in place, the effects of deployment should be judged according to a before/after comparison of these metrics. This means that metrics should not be simply a debugging mechanism (post-incident), but should act instead as an early warning measure against failed deployments.</p>\n\n<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--GDbWxTpC--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/7korybc2m6olc4xb5szl.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--GDbWxTpC--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/7korybc2m6olc4xb5szl.png" alt="With metrics" loading="lazy"></a></p>\n\n<p>Choosing what events to monitor and where to place logs is a complex process. For large applications, it is best to follow a gradual redefinition of key metrics according to past deployments. The suggested workflow is the following:</p>\n\n<ol>\n<li>Place logs and metrics on events that you guess will show a failed deployment</li>\n<li>Perform several deployments and see if your metrics can detect the failed ones</li>\n<li>If you see a failed deployment that wasn’t detected in your metrics, it means that they are not enough. Fine-tune your metrics accordingly so that the next time a deployment fails in the same manner you actually know it in advance</li>\n</ol>\n\n<p>Too many times, development teams focus on “vanity” metrics, i.e., metrics that look good on paper but say nothing about a failed deployment.</p>\n\n<h2>\n  <a name="best-practice-22-automatic-rollbacks-are-in-place" href="#best-practice-22-automatic-rollbacks-are-in-place">\n  </a>\n  Best Practice 22 – Automatic Rollbacks are in place\n</h2>\n\n<p>This is a continuation of the previous best practice. If you already have good metrics in place (that can verify the success of a deployment) you can take them to the next level by having automated rollbacks that depend on them.</p>\n\n<p>A lot of organizations have great metrics in place, but only manually use them:</p>\n\n<ol>\n<li>A developer looks at some key metrics before deployment</li>\n<li>Deployment is triggered</li>\n<li>The developer looks at the metrics in an ad-hoc manner to see what happened with the deployment</li>\n</ol>\n\n<p>While this technique is very popular, it is far from effective. Depending on the complexity of the application, the time spent watching metrics can be 1-2 hours so that the effects of the deployment have time to become visible.</p>\n\n<p>It is not uncommon for deployments to be marked as “failed” after 6-24 hours either because nobody paid attention to the correct metrics or because people simply disregarded warnings and errors thinking that was not a result of the deployment.</p>\n\n<p>Several organizations are also forced to only deploy during working hours because only at that time there are enough human eyes to look at metrics.</p>\n\n<p>Metrics should become part of the deployment process. The deployment pipeline should automatically consult metrics after a deployment happens and compare them against a known threshold or their previous state. And then in a fully automated manner, the deployment should either be marked as finished or even rolled back.</p>\n\n<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--3qDOZH9X--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/sft5m7thoznydoupmjjy.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--3qDOZH9X--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/sft5m7thoznydoupmjjy.png" alt="Automated rollbacks" loading="lazy"></a></p>\n\n<p>This is the holy grail of deployments as it completely removes the human factor out of the equation and is a step towards Continuous Deployment (instead of Continuous Delivery). With this approach:</p>\n\n<ol>\n<li>You can perform deployments at any point in time knowing that metrics will be examined with the same attention even if the time is 3 am</li>\n<li>You can catch early regressions with pinpoint accuracy</li>\n<li>Rollbacks (usually a stressful action) are now handled by the deployment platform giving easier access to the deployment process by non-technical people</li>\n</ol>\n\n<p>The result is that a developer can deploy at 5 pm on Friday and immediately go home. Either the change will be approved (and it will be still there on Monday) or it will be rolled back automatically without any ill effects (and without any downtime if you also follow best practice 20 for progressive delivery)</p>\n\n<h2>\n  <a name="best-practice-23-staging-matches-production" href="#best-practice-23-staging-matches-production">\n  </a>\n  Best Practice 23 – Staging Matches Production\n</h2>\n\n<p>We explained in best practice 12 that you should employ dynamic environments for testing individual features for developers. This gives you the confidence that each feature is correct on its own before you deploy it in production.</p>\n\n<p>It is also customary to have a single staging environment (a.k.a. pre-production) that acts as the last gateway before production. This particular environment should be as close to production as possible so that any configuration errors can and mismatches can be quickly discovered before pushing the application deployment to the real production environment.</p>\n\n<p>Unfortunately, most organizations treat the staging environment in a different way than the production one. Having a staging environment that is separate from production is a cumbersome practice as it means that you have to manually maintain it and make sure that it also gets any updates that reach production (not only in application terms but also any configuration changes).</p>\n\n<p>Two more effective ways of using a staging environment are the following:</p>\n\n<ol>\n<li>Create a staging environment on-demand each time you deploy by cloning the production environment</li>\n<li>Use as staging a special part of production (sometimes called shadow production)</li>\n</ol>\n\n<p>The first approach is great for small/medium applications and involves cloning the production environment right before a deployment happens in a similar (but possibly smaller) configuration. This means that you can also get a subset of the database and a lower number of replicas/instances that serve traffic. The important point here is that this staging environment only exists during a release. You create it just before a release and destroy it once a release has been marked as “successful”.</p>\n\n<p>The main benefit of course is that cloning your production right before deployment guarantees that you have the same configuration between staging and production. Also, there is nothing to maintain or keep up-to-date because you always discard the staging environment once the deployment has finished.</p>\n\n<p>This approach however is not realistic for large applications with many microservices or large external resources (e.g., databases and message queues). In those cases, it is much easier to use staging as a part of the production. The important point here is that the segment of production that you use does NOT get any user traffic, so in case of a failed deployment, your users will not be affected. The advantage again is that since this is part of the production you have the same guarantee that the configuration is the most recent one and what you are testing will behave in the same way as “real” production.</p>\n\n<h2>\n  <a name="applying-these-best-practices-to-your-organization" href="#applying-these-best-practices-to-your-organization">\n  </a>\n  Applying these Best Practices to Your Organization\n</h2>\n\n<p>We hope that now you have some ideas on how to improve your CI/CD process. Remember however that it is better to take gradual steps and not try to change everything at once.</p>\n\n<p>Consult the first section of this guide where we talked about priorities. Focus first on the best practices that are marked as “critical” and as soon as you have conquered them move to those with “high” importance.</p>\n\n<p>We believe that if you adopt the majority of practices that we have described in this guide, your development teams will be able to focus on shipping features instead of dealing with failed deployments and missing configuration issues.</p>\n\n<p>Cover photo by <a href="https://unsplash.com/photos/jHZ70nRk7Ns">Unsplash</a>.</p>\n\n',a.body_markdown="This is the third and last part in our “Enterprise CI/CD best practices” series. See also [part 1](https://dev.to/codefreshio/enterprise-ci-cd-best-practices-part-1-2n5m) and [part 2](https://dev.to/codefreshio/enterprise-ci-cd-best-practices-part-2-3o24) for the previous best practices.\n\n## Best Practice 16 – Database Updates have their own Lifecycle\n\nAs more and more companies adopt continuous delivery we see an alarming trend of treating databases as an external entity that exists outside of the delivery process. This could not be further from the truth.\n\nDatabases (and other supporting systems such as message queues, caches, service discovery solutions, etc.) should be handled like any other software project. This means:\n\n1. Their configuration and contents should be stored in version control\n1. All associated scripts, maintenance actions, and upgrade/downgrade instructions should also be in version control\n1. Configuration changes should be approved like any other software change (passing from automated analysis, pull request review, security scanning, unit testing, etc.)\n1. Dedicated pipelines should be responsible for installing/upgrading/rolling back each new version of the database\n\nThe last point is especially important. There are a lot of programming frameworks (e.g., rails migrations, Java Liquibase, ORM migrations) that allow the application itself to handle DB migrations. Usually the first time the application startup it can also upgrade the associate database to the correct schema. While convenient, this practice makes rollbacks very difficult and is best avoided.\n\nDatabase migration should be handled like an isolated software upgrade. You should have automated pipelines that deal only with the database, and the application pipelines should not touch the database in any way. This will give you the maximum flexibility to handle database upgrades and rollbacks by controlling exactly when and how a database upgrade takes place.\n\n## Best Practice 17 – Database Updates are Automated\n\nSeveral organizations have stellar pipelines for the application code, but pay very little attention to automation for database updates. Handling databases should be given the same importance (if not more) as with the application itself.\n\nThis means that you should similarly automate databases to application code:\n\n* Store database changesets in source control\n* Create pipelines that automatically update your database when a new changeset is created\n* Have dynamic temporary environments for databases where changesets are reviewed before being merged to mainly\n* Have code reviews and other quality checks on database changesets\n* Have a strategy for doing rollbacks after a failed database upgrade\n\nIt also helps if you automate the transformation of production data to test data that can be used in your test environments for your application code. In most cases, it is inefficient (or even impossible due to security constraints) to keep a copy of all production data in test environments. It is better to have a small subset of data that is anonymized/simplified so that it can be handled more efficiently.\n\n## Best Practice 18 – Perform Gradual Database Upgrades\n\nApplication rollbacks are well understood and we are now at the point where we have dedicated tools that perform rollbacks after a failed application deployment. And with progressively delivery techniques such as canaries and blue/green deployments, we can minimize the downtime even further.\n\nProgressive delivery techniques do not work on databases (because of the inherent state), but we can plan the database upgrades and adopt [evolutionary database design principles](https://martinfowler.com/articles/evodb.html).\n\nBy following an evolutionary design you can make all your database changesets backward and forwards compatible allowing you to rollback application and database changes at any time without any ill effects\n\nAs an example, if you want to rename a column, instead of simply creating a changeset the renames the column and performing a single database upgrade, you instead follow a schedule of gradual updates as below:\n\nDatabase changeset that only adds a new column with the new name (and copies existing data from the old column). The application code is still writing/reading from the old column\nApplication upgrade where the application code now writes to both columns but reads from the new column\nApplication upgrade where the application code writes/reads only to the new column\nDatabase upgrade that removes the old column\n\nThe process needs a well-disciplined team as it makes each database change span over several deployments. But the advantages of this process cannot be overstated. At any stage in this process, you can go back to the previous version without losing data and without the need for downtime.\n\nFor the full list of techniques see the [database refactoring website](https://databaserefactoring.com/).\n\n## Best Practice 19 – All deployments must happen via the CD platform only (and never from workstations)\n\nContinuing the theme of immutable artifacts and deployments that send to production what was deployed, we must also make sure the pipelines themselves are the only single path to production.\n\n![Single way to deploy](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/1v9y4k6ky6jqf3nkk8fe.png)\n\nThe main way to use CI/CD pipelines as intended is to make sure that the CI/CD platform is the **only** application that can deploy to production. This practice guarantees that production environments are running what they are expected to be running (i.e., the last artifact that was deployed).\n\nUnfortunately, several organizations either allow developers to deploy directly from their workstations, or even to “inject” their artifacts in a pipeline at various stages.\n\nThis is a very dangerous practice as it breaks the traceability and monitoring offered by a proper CI/CD platform. It allows developers to deploy to production features that might not be committed in source control in the first place. A lot of failed deployments stem from a missing file that was present on a developer workstation and not in source control.\n\n![Multiple ways to deploy](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/qm05nmk1eukrv5w74r4d.png)\n\nIn summary, there is only a single critical path for deployments, and this path is strictly handed by the CI/CD platform. Deploying production code from developer workstations should be prohibited at the network/access/hardware level.\n\n## Best Practice 20 – Use Progressive Deployment Patterns\n\nWe already talked about database deployments in best practice 18 and how each database upgrade should be forwards and backward compatible. This pattern goes hand-in-hand with progressive delivery patterns on the application side.\n\nTraditional deployments follow an all-or-nothing approach where all application instances move forward to the next version of the software. This is a very simple deployment approach but makes rollbacks a challenging process.\n\nYou should instead look at:\n\n1. [Blue/Green deployments](https://martinfowler.com/bliki/BlueGreenDeployment.html) that deploy a whole new set of instances of the new version, but still keep the old one for easy rollbacks\n1. [Canary releases](https://martinfowler.com/bliki/CanaryRelease.html) where only a subset of the application instances move to the new version. Most users are still routed to the previous version\n\nIf you couple these techniques with gradual database deployments, you can minimize the amount of downtime involved when a new deployment happens. Rollbacks also become a trivial process as in both cases you simply change your load balancer/service mesh to the previous configuration and all users are routed back to the original version of the application.\n\nMake sure to also look at involving your metrics (see best practices 21 and 22) in the deployment process for fully automated rollbacks.\n\n## Best Practice 21 – Metrics and logs can detect a bad deployment\n\nHaving a pipeline that deploys your application (even when you use progressive delivery) is not enough if you want to know what is the real result of the deployment. Deployments that look “successful” at first glance, but soon prove to introduce regressions is a very common occurrence in large software projects.\n\nA lot of development teams simply perform a visual check/smoke test after a deployment has finished and call it a day if everything “looks” good. But this practice is not enough and can quickly lead to the introduction of subtle bugs or performance issues.\n\n![Without metrics](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/or6337bmbdgfj4228ohk.png)\n\nThe correct approach is the adoption of application (and infrastructure) metrics. This includes:\n\n* Detailed logs for application events\n* Metrics that count and monitor key features of the application\n* Tracing information that can provide an in-depth understanding of what a single request is doing\n\nOnce these metrics are in place, the effects of deployment should be judged according to a before/after comparison of these metrics. This means that metrics should not be simply a debugging mechanism (post-incident), but should act instead as an early warning measure against failed deployments.\n\n![With metrics](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/7korybc2m6olc4xb5szl.png)\n\nChoosing what events to monitor and where to place logs is a complex process. For large applications, it is best to follow a gradual redefinition of key metrics according to past deployments. The suggested workflow is the following:\n\n1. Place logs and metrics on events that you guess will show a failed deployment\n1. Perform several deployments and see if your metrics can detect the failed ones\n1. If you see a failed deployment that wasn’t detected in your metrics, it means that they are not enough. Fine-tune your metrics accordingly so that the next time a deployment fails in the same manner you actually know it in advance\n\nToo many times, development teams focus on “vanity” metrics, i.e., metrics that look good on paper but say nothing about a failed deployment.\n\n## Best Practice 22 – Automatic Rollbacks are in place\n\nThis is a continuation of the previous best practice. If you already have good metrics in place (that can verify the success of a deployment) you can take them to the next level by having automated rollbacks that depend on them.\n\nA lot of organizations have great metrics in place, but only manually use them:\n\n1. A developer looks at some key metrics before deployment\n1. Deployment is triggered\n1. The developer looks at the metrics in an ad-hoc manner to see what happened with the deployment\n\nWhile this technique is very popular, it is far from effective. Depending on the complexity of the application, the time spent watching metrics can be 1-2 hours so that the effects of the deployment have time to become visible.\n\nIt is not uncommon for deployments to be marked as “failed” after 6-24 hours either because nobody paid attention to the correct metrics or because people simply disregarded warnings and errors thinking that was not a result of the deployment.\n\nSeveral organizations are also forced to only deploy during working hours because only at that time there are enough human eyes to look at metrics.\n\nMetrics should become part of the deployment process. The deployment pipeline should automatically consult metrics after a deployment happens and compare them against a known threshold or their previous state. And then in a fully automated manner, the deployment should either be marked as finished or even rolled back.\n\n![Automated rollbacks](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/sft5m7thoznydoupmjjy.png)\n\nThis is the holy grail of deployments as it completely removes the human factor out of the equation and is a step towards Continuous Deployment (instead of Continuous Delivery). With this approach:\n\n1. You can perform deployments at any point in time knowing that metrics will be examined with the same attention even if the time is 3 am\n1. You can catch early regressions with pinpoint accuracy\n1. Rollbacks (usually a stressful action) are now handled by the deployment platform giving easier access to the deployment process by non-technical people\n\nThe result is that a developer can deploy at 5 pm on Friday and immediately go home. Either the change will be approved (and it will be still there on Monday) or it will be rolled back automatically without any ill effects (and without any downtime if you also follow best practice 20 for progressive delivery)\n\n## Best Practice 23 – Staging Matches Production\n\nWe explained in best practice 12 that you should employ dynamic environments for testing individual features for developers. This gives you the confidence that each feature is correct on its own before you deploy it in production.\n\nIt is also customary to have a single staging environment (a.k.a. pre-production) that acts as the last gateway before production. This particular environment should be as close to production as possible so that any configuration errors can and mismatches can be quickly discovered before pushing the application deployment to the real production environment.\n\nUnfortunately, most organizations treat the staging environment in a different way than the production one. Having a staging environment that is separate from production is a cumbersome practice as it means that you have to manually maintain it and make sure that it also gets any updates that reach production (not only in application terms but also any configuration changes).\n\nTwo more effective ways of using a staging environment are the following:\n\n1. Create a staging environment on-demand each time you deploy by cloning the production environment\n1. Use as staging a special part of production (sometimes called shadow production)\n\nThe first approach is great for small/medium applications and involves cloning the production environment right before a deployment happens in a similar (but possibly smaller) configuration. This means that you can also get a subset of the database and a lower number of replicas/instances that serve traffic. The important point here is that this staging environment only exists during a release. You create it just before a release and destroy it once a release has been marked as “successful”.\n\nThe main benefit of course is that cloning your production right before deployment guarantees that you have the same configuration between staging and production. Also, there is nothing to maintain or keep up-to-date because you always discard the staging environment once the deployment has finished.\n\nThis approach however is not realistic for large applications with many microservices or large external resources (e.g., databases and message queues). In those cases, it is much easier to use staging as a part of the production. The important point here is that the segment of production that you use does NOT get any user traffic, so in case of a failed deployment, your users will not be affected. The advantage again is that since this is part of the production you have the same guarantee that the configuration is the most recent one and what you are testing will behave in the same way as “real” production.\n\n## Applying these Best Practices to Your Organization\n\nWe hope that now you have some ideas on how to improve your CI/CD process. Remember however that it is better to take gradual steps and not try to change everything at once.\n\nConsult the first section of this guide where we talked about priorities. Focus first on the best practices that are marked as “critical” and as soon as you have conquered them move to those with “high” importance.\n\nWe believe that if you adopt the majority of practices that we have described in this guide, your development teams will be able to focus on shipping features instead of dealing with failed deployments and missing configuration issues.\n\nCover photo by [Unsplash](https://unsplash.com/photos/jHZ70nRk7Ns).\n\n\n\n\n\n\n\n\n\n",a.user={name:"Kostis Kapelonis",username:"kostiscodefresh",twitter_username:e,github_username:"kostis-codefresh",website_url:"https://codefresh.io/",profile_image:"https://res.cloudinary.com/practicaldev/image/fetch/s--NAvfio9P--/c_fill,f_auto,fl_progressive,h_640,q_auto,w_640/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/437938/7b372728-0ca1-4d45-961a-b170001a220d.png",profile_image_90:"https://res.cloudinary.com/practicaldev/image/fetch/s--PeaKTpE1--/c_fill,f_auto,fl_progressive,h_90,q_auto,w_90/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/437938/7b372728-0ca1-4d45-961a-b170001a220d.png"},a.organization={name:"Codefresh",username:o,slug:o,profile_image:"https://res.cloudinary.com/practicaldev/image/fetch/s--eVMCUH5x--/c_fill,f_auto,fl_progressive,h_640,q_auto,w_640/https://dev-to-uploads.s3.amazonaws.com/uploads/organization/profile_image/3138/a894848c-dd79-44fd-b477-3af28338d874.jpg",profile_image_90:"https://res.cloudinary.com/practicaldev/image/fetch/s--iHuWL-6D--/c_fill,f_auto,fl_progressive,h_90,q_auto,w_90/https://dev-to-uploads.s3.amazonaws.com/uploads/organization/profile_image/3138/a894848c-dd79-44fd-b477-3af28338d874.jpg"},{layout:"default",data:[{}],fetch:{"data-v-70afb46a:0":{article:a}},error:e,state:{currentArticle:a},serverRendered:!0,routePath:"/kostiscodefresh/727810",config:{_app:{basePath:"/nuxtstop/",assetsPath:"/nuxtstop/_nuxt/",cdnURL:e}}}}(null,"2021-06-14T10:30:17Z",{},"codefreshio")</script><script src="/nuxtstop/_nuxt/f6e87fb.js" defer></script><script src="/nuxtstop/_nuxt/dc9ce94.js" defer></script><script src="/nuxtstop/_nuxt/6474719.js" defer></script><script src="/nuxtstop/_nuxt/9b75090.js" defer></script><script src="/nuxtstop/_nuxt/18df600.js" defer></script>
  </body>
</html>
