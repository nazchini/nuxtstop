<!doctype html>
<html data-n-head-ssr lang="en" data-n-head="%7B%22lang%22:%7B%22ssr%22:%22en%22%7D%7D">
  <head>
    <title>Introducing VoiceCue - Find sentiments, tags, entities, actions like a DJ üßô‚ú®</title><meta data-n-head="ssr" charset="utf-8"><meta data-n-head="ssr" name="viewport" content="width=device-width,initial-scale=1"><meta data-n-head="ssr" data-hid="description" name="description" content="Using Nuxt.js fetch() hook to build dev.to with a new look"><meta data-n-head="ssr" name="format-detection" content="telephone=no"><base href="/nuxtstop/"><link data-n-head="ssr" rel="icon" type="image/x-icon" href="/favicon.ico"><link data-n-head="ssr" rel="stylesheet" href="https://fonts.googleapis.com/css?family=Inter:400,500,600&display=swap"><link rel="preload" href="/nuxtstop/_nuxt/f6e87fb.js" as="script"><link rel="preload" href="/nuxtstop/_nuxt/6474719.js" as="script"><link rel="preload" href="/nuxtstop/_nuxt/9b75090.js" as="script"><link rel="preload" href="/nuxtstop/_nuxt/18df600.js" as="script"><link rel="preload" href="/nuxtstop/_nuxt/dc9ce94.js" as="script"><style data-vue-ssr-id="c650fd98:0 af4684f0:0 a9c71758:0 dcafa518:0 4b9cec49:0 b093d766:0 9d98bcb4:0 6b6a11ea:0 0248ed80:0 ea8e4264:0">html{box-sizing:border-box;font-family:sans-serif;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}*,:after,:before{box-sizing:inherit}html{font-family:-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Noto Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";line-height:1.5}*,:after,:before{border:0 solid #e0e0e0}blockquote,body,dd,dl,figure,h1,h2,h3,h4,h5,h6,p,pre{margin:0}button{background:0 0;padding:0}button:focus{outline:1px dotted;outline:5px auto -webkit-focus-ring-color}fieldset,ol,ul{margin:0;padding:0}ol,ul{list-style:none}hr{border-width:1px}img{border-style:solid}textarea{resize:vertical}input::-moz-placeholder,textarea::-moz-placeholder{color:inherit;opacity:.5}input:-ms-input-placeholder,textarea:-ms-input-placeholder{color:inherit;opacity:.5}input::placeholder,textarea::placeholder{color:inherit;opacity:.5}[role=button],button{cursor:pointer}table{border-collapse:collapse}h1,h2,h3,h4,h5,h6{font-size:inherit;font-weight:inherit;font-family:sans-serif}a{color:inherit;text-decoration:inherit}button,input,optgroup,select,textarea{padding:0;line-height:inherit;color:inherit;font-family:inherit;font-size:100%}code,kbd,pre,samp{font-family:SFMono-Regular,Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace;overflow:auto;word-break:break-word;white-space:normal}audio,canvas,embed,iframe,img,object,svg,video{display:block;vertical-align:middle}img,video{max-width:100%;height:auto}html{height:100%;font-size:18px;-ms-overflow-style:scrollbar;-webkit-tap-highlight-color:transparent;-webkit-touch-callout:none}@media(min-width:640px){html{font-size:20px}}body{height:100%;min-width:320px;font-family:Inter,-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Noto Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";font-weight:400;line-height:1.5;color:#000;background-color:#eff4f7;-webkit-text-rendering:optimizeLegibility;text-rendering:optimizeLegibility;font-synthesis:none;font-kerning:normal;font-feature-settings:"normal","kern";-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;-webkit-overflow-scrolling:touch;overflow-x:hidden;overflow-y:scroll}h1,h2,h3,h4,h5,h6{color:#000;font-family:Inter,-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Noto Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";font-weight:600;font-feature-settings:"normal";line-height:1.2}pre{background:#29292e;border-radius:2px;overflow:auto;padding:1rem;color:#eff1f9;line-height:1.42em;font-size:13px}@media screen and (min-width:380px){pre{font-size:15px}}pre code{background:#29292e;color:#eff0f9;white-space:pre}div.highlight pre.highlight code{font-size:inherit;padding:0}div.inner-comment div.body div.highlight pre.highlight{background:#29292e}div.inner-comment div.body div.highlight pre.highlight code{font-size:inherit;white-space:inherit;background:inherit;color:inherit}.highlight .hll{background-color:#49483e}.highlight{background:#29292e;color:#f8f8f2}.highlight .c{color:grey}.highlight .err{text-shadow:0 0 7px #f9690e}.highlight .k{color:#f39c12}.highlight .l{color:plum}.highlight .n{color:#f8f8f2}.highlight .o{color:#f9690e}.highlight .p{color:#f8f8f2}.highlight .c1,.highlight .ch,.highlight .cm,.highlight .cp,.highlight .cpf,.highlight .cs{color:grey}.highlight .gd{color:#f9690e}.highlight .ge{font-style:italic}.highlight .gi{color:#7ed07e}.highlight .gs{font-weight:700}.highlight .gu{color:grey}.highlight .kc,.highlight .kd{color:#f39c12}.highlight .kn{color:#f9690e}.highlight .kp,.highlight .kr,.highlight .kt{color:#f39c12}.highlight .ld{color:#f2ca27}.highlight .m{color:plum}.highlight .s{color:#f2ca27}.highlight .na{color:#7ed07e}.highlight .nb{color:#f8f8f2}.highlight .nc{color:#7ed07e}.highlight .no{color:#f39c12}.highlight .nd{color:#7ed07e}.highlight .ni{color:#f8f8f2}.highlight .ne,.highlight .nf{color:#7ed07e}.highlight .nl,.highlight .nn{color:#f8f8f2}.highlight .nx{color:#7ed07e}.highlight .py{color:#f8f8f2}.highlight .nt{color:#f9690e}.highlight .nv{color:#f8f8f2}.highlight .ow{color:#f9690e}.highlight .w{color:#f8f8f2}.highlight .mb,.highlight .mf,.highlight .mh,.highlight .mi,.highlight .mo{color:plum}.highlight .dl,.highlight .s2,.highlight .sa,.highlight .sb,.highlight .sc,.highlight .sd{color:#f2ca27}.highlight .se{color:plum}.highlight .s1,.highlight .sh,.highlight .si,.highlight .sr,.highlight .ss,.highlight .sx{color:#f2ca27}.highlight .bp{color:#f8f8f2}.highlight .fm{color:#7ed07e}.highlight .vc,.highlight .vg,.highlight .vi,.highlight .vm{color:#f8f8f2}.highlight .il{color:plum}.vue-content-placeholders-heading__img,.vue-content-placeholders-heading__subtitle,.vue-content-placeholders-heading__title,.vue-content-placeholders-img,.vue-content-placeholders-text__line{background:#bfcdec!important}.vue-content-placeholders-is-animated .vue-content-placeholders-heading__img:before,.vue-content-placeholders-is-animated .vue-content-placeholders-heading__subtitle:before,.vue-content-placeholders-is-animated .vue-content-placeholders-heading__title:before,.vue-content-placeholders-is-animated .vue-content-placeholders-img:before,.vue-content-placeholders-is-animated .vue-content-placeholders-text__line:before{background:linear-gradient(90deg,transparent 0,#d3ddf9 15%,transparent 30%)!important}header[data-v-27046cca]{max-width:1280px;margin:auto;padding:1rem;height:6rem;border-bottom:1px solid rgba(0,0,0,.2)}header .logo-wrapper[data-v-27046cca],header[data-v-27046cca]{display:flex;align-items:center;justify-content:space-between}header .logo-wrapper[data-v-27046cca]{margin:0 .5rem}header .logo-wrapper svg[data-v-27046cca]{width:3rem;height:100%}header .logo-wrapper .name-wrapper[data-v-27046cca]{margin-left:.6em}header .logo-wrapper .name-wrapper .subtitle[data-v-27046cca]{font-size:1rem}header .logo-wrapper .name-wrapper .app-name[data-v-27046cca]{font-weight:700;font-size:2.25rem;line-height:1.25}header nav[data-v-27046cca]{letter-spacing:-.025rem;font-weight:600;text-transform:uppercase}header nav ul[data-v-27046cca]{display:flex}header nav ul li[data-v-27046cca]{margin:0 .5rem}header nav ul li a[data-v-27046cca]{box-shadow:-4px -4px 8px #f8fafe,4px 4px 8px #ced2db;padding:.25rem 1rem;border-radius:.5rem;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}header nav ul li a[data-v-27046cca]:hover{background:linear-gradient(135deg,rgba(0,0,0,.09),hsla(0,0%,100%,0))}header nav ul li a.nuxt-link-exact-active[data-v-27046cca]{cursor:default}header nav ul li a.nuxt-link-exact-active[data-v-27046cca],header nav ul li a[data-v-27046cca]:active{background:0 0;box-shadow:inset -4px -4px 8px #f0f3f9,inset 4px 4px 8px #ced2db,inset -1px -1px 4px #8e8e8e}.page-wrapper[data-v-10d06ee8]{max-width:1280px;margin:auto;padding:1rem}.article-content-wrapper[data-v-10d06ee8]{display:flex;flex-direction:column;align-items:center;margin:auto auto 2rem}@media(min-width:1024px){.article-content-wrapper[data-v-10d06ee8]{align-items:normal;flex-direction:row}}.article-content-wrapper .article-block[data-v-10d06ee8]{width:100%;max-width:880px}@media(min-width:1024px){.article-content-wrapper .article-block[data-v-10d06ee8]{margin-right:1rem;width:66.66666%;margin-bottom:2rem}}.article-content-wrapper .aside-username-wrapper[data-v-10d06ee8]{max-width:880px;width:100%;position:relative}@media(min-width:1024px){.article-content-wrapper .aside-username-wrapper[data-v-10d06ee8]{display:block;width:33.33333%}}.article-content-wrapper .aside-username-wrapper .aside-username-block[data-v-10d06ee8]{position:-webkit-sticky;position:sticky;top:1rem}@media(min-width:1280px){.comments-block[data-v-10d06ee8]{margin:.5rem}}article[data-v-70afb46a]{padding:.5rem;border-radius:1rem}header h1[data-v-70afb46a],header[data-v-70afb46a]{margin-bottom:1rem}header h1[data-v-70afb46a]{font-size:2.25rem;letter-spacing:-.025rem}header .tags[data-v-70afb46a]{display:flex;flex-wrap:wrap;margin-bottom:1.5rem}header .tags .tag[data-v-70afb46a]{font-weight:500;line-height:1;padding:.5rem;margin:0 .5rem .5rem 0;border-radius:.25rem;box-shadow:-4px -4px 8px #f8fafe,4px 4px 8px #ced2db}header .tags .tag[data-v-70afb46a]:hover{background:linear-gradient(135deg,rgba(0,0,0,.09),hsla(0,0%,100%,0))}header .tags .tag[data-v-70afb46a]:active{background:0 0;box-shadow:inset -4px -4px 8px #f0f3f9,inset 4px 4px 8px #ced2db,inset -1px -1px 4px #8e8e8e}header .image-wrapper[data-v-70afb46a]{position:relative;padding-bottom:56.25%;background-color:#d4dfe8;margin-bottom:1.5rem;border-radius:.5rem;overflow:hidden}@media(min-width:834px){header .image-wrapper[data-v-70afb46a]{margin-bottom:1.5rem}}header .image-wrapper img[data-v-70afb46a]{position:absolute;top:0;left:0;width:100%;height:100%;-o-object-fit:cover;object-fit:cover}header .meta[data-v-70afb46a]{line-height:1;font-size:.875rem;text-transform:uppercase;font-weight:500;letter-spacing:-.025rem;display:flex;align-items:center;justify-content:space-between}header .meta .scl[data-v-70afb46a]{display:flex}header .meta .scl span[data-v-70afb46a]{display:flex;align-items:center;margin-right:1rem}header .meta .scl span svg[data-v-70afb46a]{margin-right:.25rem}header .meta .scl .comments[data-v-70afb46a]{cursor:pointer}[data-v-70afb46a] .content .ltag__user{display:none}[data-v-70afb46a] .content iframe{max-width:100%}[data-v-70afb46a] .content h1{font-size:1.875rem}[data-v-70afb46a] .content h1,[data-v-70afb46a] .content h2{margin-top:2rem;margin-bottom:1rem;letter-spacing:-.025rem}[data-v-70afb46a] .content h2{font-size:1.5rem}[data-v-70afb46a] .content h3{font-size:1.25rem}[data-v-70afb46a] .content h3,[data-v-70afb46a] .content h4{margin-top:2rem;margin-bottom:1rem;letter-spacing:-.025rem}[data-v-70afb46a] .content h4{font-size:1rem}[data-v-70afb46a] .content a{color:#6e87d2}[data-v-70afb46a] .content p{margin-bottom:1rem;line-height:1.4}[data-v-70afb46a] .content p code{background-color:#d2f3e1;border-radius:.25rem;padding:.25rem}[data-v-70afb46a] .content img{width:100%;border-radius:.5rem}[data-v-70afb46a] .content .highlight{margin-bottom:1rem;border-radius:.5rem}[data-v-70afb46a] .content ul{list-style:numeral;margin-bottom:1rem}[data-v-70afb46a] .content ul li p{margin-bottom:0}[data-v-70afb46a] .content ol{margin-bottom:1rem}aside[data-v-37984f8c]{padding:1rem;background-color:#dfe8ef;border-radius:1rem}aside .username-heading[data-v-37984f8c]{display:flex;margin-bottom:1rem}aside .username-heading[data-v-37984f8c]:hover{color:#6e87d2}aside .username-heading img[data-v-37984f8c]{width:3rem;height:3rem;border-radius:50%;margin-right:1rem}aside .username-heading .text[data-v-37984f8c]{display:flex;flex-direction:column;justify-content:center}aside .username-heading .text a[data-v-37984f8c]{line-height:1}aside .username-heading .text a[data-v-37984f8c]:first-child{font-size:1.25rem;font-weight:500;letter-spacing:-.025rem;margin-bottom:.25rem}aside .username-heading .text a[data-v-37984f8c]:last-child{color:#999;font-size:.875rem}aside .username-heading.loading[data-v-37984f8c]{display:block}aside .f-button[data-v-37984f8c]{display:block;width:100%;padding:.5rem;border-radius:.5rem;box-shadow:-4px -4px 8px #f8fafe,4px 4px 8px #ced2db;text-transform:uppercase;text-align:center;font-weight:600;letter-spacing:-.025rem;margin-bottom:1rem}aside .f-button[data-v-37984f8c]:hover{background:linear-gradient(135deg,rgba(0,0,0,.09),hsla(0,0%,100%,0))}aside .f-button[data-v-37984f8c]:active{background:0 0;box-shadow:inset -4px -4px 8px #f0f3f9,inset 4px 4px 8px #ced2db,inset -1px -1px 4px #8e8e8e}aside .info>div[data-v-37984f8c]{margin-bottom:.5rem}aside .info .title[data-v-37984f8c]{font-size:.666666rem;letter-spacing:-.0125rem;font-weight:500;color:#999;text-transform:uppercase;margin-bottom:.1rem}aside .info .content[data-v-37984f8c]{font-size:.875rem;line-height:1.4}.add-comment[data-v-8c4375bc]{display:block;width:100%;padding:.5rem;border-radius:.5rem;box-shadow:-4px -4px 8px #f8fafe,4px 4px 8px #ced2db;text-transform:uppercase;text-align:center;font-weight:600;letter-spacing:-.025rem;margin-bottom:1rem}.add-comment[data-v-8c4375bc]:hover{background:linear-gradient(135deg,rgba(0,0,0,.09),hsla(0,0%,100%,0))}.add-comment[data-v-8c4375bc]:active{background:0 0;box-shadow:inset -4px -4px 8px #f0f3f9,inset 4px 4px 8px #ced2db,inset -1px -1px 4px #8e8e8e}footer[data-v-22cb8fd0]{padding:2rem;text-align:center;display:flex;align-items:center;justify-content:center}footer span[data-v-22cb8fd0]{display:inline-block;line-height:1;text-transform:uppercase;letter-spacing:-.025rem;font-size:.75rem;font-weight:500}footer a svg[data-v-22cb8fd0]{width:3rem;height:3rem;margin:0 .5rem}footer a .nuxt-icon[data-v-22cb8fd0]{width:2.5rem;height:2.5rem;margin:0 .25rem}</style>
  </head>
  <body>
    <div data-server-rendered="true" id="__nuxt"><div id="__layout"><div><header data-v-27046cca><a href="/nuxtstop/" class="logo-wrapper nuxt-link-active" data-v-27046cca><svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" data-v-27046cca><path d="M13.5599 8.54348L12.8055 9.87164L10.2257 5.3282L2.306 19.274H7.66815C7.66815 20.0075 8.25298 20.6021 8.97441 20.6021H2.306C1.83937 20.6021 1.40822 20.3489 1.17494 19.9379C0.941664 19.527 0.941687 19.0208 1.175 18.6099L9.09469 4.66412C9.32802 4.25316 9.75926 4 10.226 4C10.6926 4 11.1239 4.25316 11.3572 4.66412L13.5599 8.54348V8.54348Z" fill="#00C58E" data-v-27046cca></path><path d="M19.2769 18.6099L14.3143 9.87165L13.5599 8.54348L12.8055 9.87165L7.84343 18.6099C7.61011 19.0208 7.61009 19.527 7.84337 19.9379C8.07665 20.3489 8.50779 20.6021 8.97443 20.6021H18.1443C18.611 20.6021 19.0424 20.3491 19.2758 19.9382C19.5092 19.5272 19.5092 19.0209 19.2758 18.6099H19.2769ZM8.97443 19.274L13.5599 11.1998L18.1443 19.274H8.97443H8.97443Z" fill="#2F495E" data-v-27046cca></path><path d="M22.825 19.938C22.5917 20.3489 22.1606 20.6021 21.694 20.6021H18.1443C18.8657 20.6021 19.4505 20.0075 19.4505 19.274H21.6913L15.3331 8.07696L14.3142 9.87164L13.5599 8.54348L14.2021 7.41287C14.4354 7.00192 14.8667 6.74875 15.3334 6.74875C15.8001 6.74875 16.2313 7.00192 16.4646 7.41287L22.825 18.6099C23.0583 19.0208 23.0583 19.5271 22.825 19.938V19.938Z" fill="#108775" data-v-27046cca></path></svg> <div class="name-wrapper" data-v-27046cca><span class="app-name" data-v-27046cca>Nuxtstop</span> <p class="subtitle" data-v-27046cca>For all things nuxt.js</p></div></a> <nav data-v-27046cca><ul data-v-27046cca><li data-v-27046cca><a href="/nuxtstop/" class="nuxt-link-active" data-v-27046cca>
          New
        </a></li><li data-v-27046cca><a href="/nuxtstop/top" data-v-27046cca>
          Top
        </a></li></ul></nav></header> <div class="page-wrapper" data-v-10d06ee8><div class="article-content-wrapper" data-v-10d06ee8><article data-fetch-key="data-v-70afb46a:0" class="article-block" data-v-70afb46a data-v-10d06ee8><header data-v-70afb46a><h1 data-v-70afb46a>Introducing VoiceCue - Find sentiments, tags, entities, actions like a DJ üßô‚ú®</h1> <div class="tags" data-v-70afb46a><a href="/nuxtstop/t/hackwithdg" class="tag" data-v-70afb46a>
          #hackwithdg
        </a><a href="/nuxtstop/t/deepgram" class="tag" data-v-70afb46a>
          #deepgram
        </a><a href="/nuxtstop/t/deeplearning" class="tag" data-v-70afb46a>
          #deeplearning
        </a><a href="/nuxtstop/t/ai" class="tag" data-v-70afb46a>
          #ai
        </a></div> <div class="image-wrapper" data-v-70afb46a><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--mQnE4mM0--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/h6ldp523x7e65wu4t6r6.png" alt="Introducing VoiceCue - Find sentiments, tags, entities, actions like a DJ üßô‚ú®" data-v-70afb46a></div> <div class="meta" data-v-70afb46a><div class="scl" data-v-70afb46a><span data-v-70afb46a><svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" data-v-70afb46a data-v-70afb46a><path d="M16.4444 3C14.6733 3 13.0333 3.94162 12 5.34C10.9667 3.94162 9.32667 3 7.55556 3C4.49222 3 2 5.52338 2 8.625C2 14.8024 11.0267 20.586 11.4122 20.829C11.5922 20.9426 11.7956 21 12 21C12.2044 21 12.4078 20.9426 12.5878 20.829C12.9733 20.586 22 14.8024 22 8.625C22 5.52338 19.5078 3 16.4444 3Z" fill="#FF0000" data-v-70afb46a data-v-70afb46a></path></svg>
            57
          </span> <span class="comments" data-v-70afb46a><svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" data-v-70afb46a data-v-70afb46a><path d="M6.11765 22H4.94118L5.64706 21.05C6.11765 20.3969 6.41176 19.5656 6.58824 18.5563C3.64706 17.1906 2 14.6375 2 11.3125C2 6.20625 5.82353 3 12 3C18.1765 3 22 6.20625 22 11.3125C22 16.5375 18.2353 19.625 12 19.625H11.5882C10.6471 20.7531 9 22 6.11765 22ZM12 4.1875C6.47059 4.1875 3.17647 6.85937 3.17647 11.3125C3.17647 15.1125 5.47059 16.8938 7.41177 17.6656L7.82353 17.8437L7.76471 18.3187C7.64706 19.2687 7.47059 20.1 7.11765 20.8125C9.05882 20.575 10.1765 19.5656 10.8235 18.7344L11 18.4969H12C19.9412 18.4969 20.8235 13.5094 20.8235 11.3719C20.8235 6.85938 17.5294 4.1875 12 4.1875Z" fill="black" data-v-70afb46a data-v-70afb46a></path></svg>
            8
          </span></div> <time data-v-70afb46a>Apr 10</time></div></header> <div class="content" data-v-70afb46a><h3>
  <a name="overview-of-my-submission" href="#overview-of-my-submission">
  </a>
  Overview of My Submission
</h3>

<p>Many of us have come across the tidy task of voice recording analysis, where you had to listen to the whole audio to identify the most essential parts.</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--5oDaNQit--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/7gxdx8eq4ocwhe6fd8g2.jpeg" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--5oDaNQit--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/7gxdx8eq4ocwhe6fd8g2.jpeg" alt="Problem" loading="lazy" width="880" height="380"></a></p>

<p>Manual processing can be very time-inefficient. Just listening from end to end would often not be enough. You would have to double or even triple that time since you would have to pause and replay some parts of the audio.</p>

<p>During the mid-March to mid-April, I came up with <a href="https://cue.madza.dev">VoiceCue</a>, an app that generates cue timecodes that lets you find all the important parts of your voice recordings like sentiments, entities, and tags with just a click.</p>

<p>In this article, we will review it.</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--0ynolo2s--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/n4qxutv8g1ks063dvahn.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--0ynolo2s--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/n4qxutv8g1ks063dvahn.png" alt="Preview" loading="lazy" width="880" height="426"></a></p>

<p>This project was built specifically as an entry for the <a href="https://dev.com">DEV</a> and <a href="https://deepgram.com">Deepgram</a> hackathon. It was an awesome experience since the participation motivated me and I came up with a product that could hopefully benefit others as well.</p>

<h3>
  <a name="submission-category" href="#submission-category">
  </a>
  Submission Category
</h3>

<p>The root idea of the application comes from the world famous DJs in the music industry. Before the gigs they set cues for the audio tracks that they will play, marking the breakdown, drop, outro and so on. This way they can find specific parts quickly if they need to.</p>

<p>Thanks to <a href="https://developers.deepgram.com/api-reference/">Deepgram API</a> I was able to implement my own cue system and pair it with the analysis of voice recordings. The cues are being generated for positive and negative sentiments, frequently used words, numerous entities, and actions as well as custom search queries.</p>

<p>I've never seen an AI-based cue tool for voice recordings, so I thought the perfect category for this would be <strong>Wacky Wildcards</strong>.</p>

<h3>
  <a name="link-to-code-githubcommadzadevvoicecue" href="#link-to-code-githubcommadzadevvoicecue">
  </a>
  Link to Code: <a href="https://github.com/madzadev/voice-cue">github.com/madzadev/voice-cue</a> üßë‚Äçüíª
</h3>

<h3>
  <a name="deployed-app-cuemadzadev" href="#deployed-app-cuemadzadev">
  </a>
  Deployed app: <a href="https://cue.madza.dev">cue.madza.dev</a> üéâ
</h3>


<hr>

<h3>
  <a name="how-does-it-work" href="#how-does-it-work">
  </a>
  How does it work?
</h3>

<p>An audio cue is basically a shortcut that lets you jump to a predefined position in the audio.</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--OyUFqKcZ--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/32ztu18a7jasb9iyts49.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--OyUFqKcZ--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/32ztu18a7jasb9iyts49.png" alt="Waveform" loading="lazy" width="880" height="118"></a></p>

<p>The app workflow is as simple as uploading your voice recording, selecting which type of analysis to perform, and clicking on the generated cues in the list to instantly navigate to its exact position in the voice recording. </p>

<h3>
  <a name="overview-and-stats" href="#overview-and-stats">
  </a>
  Overview and stats
</h3>

<p>Overview statistics gives an overall summary of the recording.</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--xbDCC8oG--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/639ydh7mn9py3xkqz98s.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--xbDCC8oG--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/639ydh7mn9py3xkqz98s.png" alt="Statistics" loading="lazy" width="810" height="291"></a></p>

<p>The analysis include: total characters, sentences and words, total identified sentiment cues and their cumulative tone score, as well as total identified tags, named entities, actions and speakers count in the voice recording.</p>

<h3>
  <a name="interactive-transcript" href="#interactive-transcript">
  </a>
  Interactive transcript
</h3>

<p>The generated transcript is interactive, highlighting the words as they are heard in the voice recording. This feature makes it easier to track the current position in the overall context as well as increases accessibility for people with hearing problems.</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--6NPvNHwx--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/ku3oijoi0h5d16p7y94g.gif" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--6NPvNHwx--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/ku3oijoi0h5d16p7y94g.gif" alt="Interactive transcript" loading="lazy" width="880" height="425" data-animated="true"></a></p>

<p>Furthermore, user can click on any word on the transcript and the audio progress will be automatically set to the position of the word in the voice recording.</p>

<p>The audio waveform lets user visually perceive the dynamics of the voice and identify silences. For playback, the user can switch between audio controls and manually adjusting the progress marker on the waveform.</p>

<h3>
  <a name="sentiment-analysis" href="#sentiment-analysis">
  </a>
  Sentiment analysis
</h3>

<p>Sentiment analysis checks against the words with positive and negative meanings.</p>

<p>After selecting the sentiment, the list of sentiment words is returned. The header shows the selected sentiment and how many words of that sentiment appeared in the voice recording.</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--NPjri7FJ--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/pt2m8ybs9m64smjcvxxf.gif" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--NPjri7FJ--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/pt2m8ybs9m64smjcvxxf.gif" alt="Sentiment analysis" loading="lazy" width="880" height="425" data-animated="true"></a></p>

<p>Each individual tag in the list displays the word, timecode, and its sentiment rank on the scale from -4 for the negative to +4 for the positive words.</p>

<p>There are various practical use cases for both. For example, the user might check the positive sentiment to compile a list of referrals for personal website. Or he/she might check the negative sentiment to get some feedback on what to improve on it.</p>

<h3>
  <a name="tag-cloud" href="#tag-cloud">
  </a>
  Tag cloud
</h3>

<p>The tag cloud returns the most used words in the voice recording. </p>

<p>The higher the number of occurrences in the recording, the bigger the font size for the tag is used in the cloud. Also, a different color scheme is used for each tag so it is easier to distinguish.</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--le5XTdFt--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/u6x00uw3uq2y2pjvtau2.gif" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--le5XTdFt--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/u6x00uw3uq2y2pjvtau2.gif" alt="Tag cloud" loading="lazy" width="880" height="425" data-animated="true"></a></p>

<p>After a tag is selected the list header shows how many times the tag occurred throughout the recording. For individual cues, the sequence of appearance is shown along with the time code.</p>

<p>By looking at the word cloud it is easy to understand what were the main topics of the conversation. This could be very useful if someone wants to see what products or services are mentioned the most, for example.</p>

<h3>
  <a name="named-entities" href="#named-entities">
  </a>
  Named entities
</h3>

<p>Named entity analysis lets you find cues based on word categorization. </p>

<p>Currently supported named entities are Person, Place, Organization, Money, Unit, and Date.</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--OP6JbJH1--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/2abgsz5bjr94mecs8uwx.gif" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--OP6JbJH1--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/2abgsz5bjr94mecs8uwx.gif" alt="Named entities" loading="lazy" width="880" height="425" data-animated="true"></a></p>

<p>When a named entity is selected, the number of total occurrences on the recording is displayed in the header. Each individual generated cue represents the specific word of the entity, its sequence of appearance as well as the timecode.</p>

<p>Named entities can be very useful. For example, a company would check for a Person entity to quickly generate timecodes for the mentions of board members in the recording. Or search for Money entity to quickly jump to where the company budget is mentioned.</p>

<h3>
  <a name="actions" href="#actions">
  </a>
  Actions
</h3>

<p>Actions analysis returns the verbs, by categorizing them into past, present, and future. Currently supported categories are PastTense, Infinitive, Copula, Modal, and Gerund.</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--Wf1CybA5--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/4yket479qjp6zkt52g1e.gif" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--Wf1CybA5--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/4yket479qjp6zkt52g1e.gif" alt="Actions" loading="lazy" width="880" height="425" data-animated="true"></a></p>

<p>Similar to named entities, once the action is selected, it is displayed on the list header with the number of total occurrences on the recording. Each individual generated cue represents the specific word of the action, its sequence of appearance as well as the time code.</p>

<p>Thanks to the categorization by the tense, action cues can be practically used if someone wants to find information about topics such as accomplished milestones, current processes, or planned tasks for the future.</p>

<h3>
  <a name="custom-search" href="#custom-search">
  </a>
  Custom search
</h3>

<p>If you were not able to find the cue you were looking for via any of the previous analysis methods, there is a custom search that let you search for custom words as well.</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--RFWlcWQ3--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/91vzlju8ngvszi3n800i.gif" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--RFWlcWQ3--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/91vzlju8ngvszi3n800i.gif" alt="Custom search" loading="lazy" width="880" height="425" data-animated="true"></a></p>

<p>The user is required to enter at least 3 characters to generate the list of cues. If the search query returns multiple cues, all are displayed below each other, with the word that includes the query, its sequence number, and timecode. </p>

<h3>
  <a name="responsiveness" href="#responsiveness">
  </a>
  Responsiveness
</h3>

<p>In our daily lives, we usually use phones to interview someone or record a meeting or event. Therefore making the app fully responsive to different screen widths was among the main priorities. </p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--nla7bPea--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/s4rdk6sig5ksikovwpuc.gif" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--nla7bPea--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/s4rdk6sig5ksikovwpuc.gif" alt="Mobile screen" loading="lazy" width="880" height="514" data-animated="true"></a></p>

<p>Since all the features are supported on smaller screens as well, the application is ready to be used in every situation, anytime you have a device with you.</p>

<h3>
  <a name="features-list" href="#features-list">
  </a>
  Features list:
</h3>

<ol>
<li><p>Voice recognition - based on the <a href="https://developers.deepgram.com/">Deepgram API</a></p></li>
<li><p>General stats - an overview of voice recording</p></li>
<li><p>Sentiment analysis - positive and negative word detection</p></li>
<li><p>Word cloud generation - most used word classification</p></li>
<li><p>Entity name recognition - categories such as person, place, etc</p></li>
<li><p>Activity tracking - find actions in past, present, or future</p></li>
<li><p>Interactive transcript - see progress or click to control it</p></li>
<li><p>Speaker detection - total number of speakers in recording</p></li>
<li><p>Cue word usage - short text samples for better context</p></li>
<li><p>Custom search - extended ability to query for cues</p></li>
<li><p>Waveform preview - see the dynamics of voice, identify silences</p></li>
<li><p>Audio controls - play, pause, fast forward, and backward</p></li>
<li><p>Drag and drop support - drop audio in the file select area</p></li>
<li><p>Upload MP3 files - the most commonly used audio format</p></li>
<li><p>Progress loaders  - improved UX for loading transcripts</p></li>
<li><p>Fully responsive - works fine on mobile and tablets</p></li>
<li><p>Colorful UI - for easier interaction and word highlighting</p></li>
</ol>

<h3>
  <a name="tech-stack" href="#tech-stack">
  </a>
  Tech stack
</h3>

<p><a href="https://nextjs.org">NextJS</a> - React application framework</p>

<p><a href="https://deepgram.com">Deepgram</a> - for AI-based speech recognition</p>

<p><a href="https://www.npmjs.com/package/compromise">compromise</a>, <a href="https://www.npmjs.com/package/sentiment">sentiment</a> - for text processing</p>

<p><a href="https://www.npmjs.com/package/react-tagcloud">react-tagcloud</a> - to generate word cloud</p>

<p><a href="https://www.npmjs.com/package/react-tabs">react-tabs</a> - for navigation panels</p>

<p><a href="https://www.npmjs.com/package/react-drag-drop-files">react-drag-drop-files</a> - for drag and drop support</p>

<p><a href="https://www.npmjs.com/package/wavesurfer.js">wavesurfer.js</a> - to generate the audio waveform</p>

<p><a href="https://github.com">GitHub</a> - to host the code</p>

<p><a href="https://vercel.com">Vercel</a> - to deploy the project</p>

<p><a href="https://eslint.org/">ESLint</a>, <a href="https://prettier.io/">prettier</a> - for linting and code formatting</p>

<p><a href="https://namecheap.com">Namecheap</a> - for custom subdomain</p>

<h3>
  <a name="conclusion" href="#conclusion">
  </a>
  Conclusion
</h3>

<p>I want to thank <a href="https://www.forem.com/">Forem</a> for providing a great platform to learn, share findings, and engage with awesome people. Visiting <a href="https://dev.to">DEV</a> daily has become a habit of mine for years and I have already published 300+ posts.</p>

<p>It was my pleasure to discover <a href="https://deepgram.com">Deepgram</a>, a co-host for this hackathon providing their API to build awesome stuff with. From now on I will have a valuable tool in my pocket that I will already know how to use when I will have to deal with speech recognition projects. </p>

<p>The voice is an instrument of communication, lots of valuable information is being transferred with it every second. The powerful API of <a href="https://deepgram.com">Deepgram</a> is a wide step toward working smart, not hard, which will become an even more crucial skill to beat the competition in the future.</p>


<hr>

<p>Building projects have always been my passion and it gives me pleasure to help and inspire people. If you have any questions, feel free to reach out!</p>

<p>Connect me on <a href="https://twitter.com/madzadev">Twitter</a>, <a href="https://www.linkedin.com/in/madzadev/">LinkedIn</a> and <a href="https://github.com/madzadev">GitHub</a>!</p>

<p>Visit my <a href="https://madza.dev/code">Portfolio</a> for more projects like this.</p>

</div></article> <div class="aside-username-wrapper" data-v-10d06ee8><aside class="aside-username-block" data-v-37984f8c data-v-10d06ee8><div class="username-heading loading" data-v-37984f8c><div class="vue-content-placeholders vue-content-placeholders-is-animated" data-v-37984f8c><div class="vue-content-placeholders-heading" data-v-37984f8c><div class="vue-content-placeholders-heading__img"></div> <div class="vue-content-placeholders-heading__content"><div class="vue-content-placeholders-heading__title"></div> <div class="vue-content-placeholders-heading__subtitle"></div></div></div></div></div> <div class="info" data-v-37984f8c><div class="vue-content-placeholders vue-content-placeholders-is-animated" data-v-37984f8c><div class="vue-content-placeholders-text" data-v-37984f8c><div class="vue-content-placeholders-text__line"></div><div class="vue-content-placeholders-text__line"></div><div class="vue-content-placeholders-text__line"></div></div></div></div></aside></div></div> <div class="comments-block" data-v-8c4375bc data-v-10d06ee8><!----> <a href="https://dev.to/madza/introducing-voicecue-find-sentiments-tags-entities-actions-like-a-dj-4kjk" target="_blank" rel="nofollow noopener noreferer" class="add-comment" data-v-8c4375bc>
    Add comment
  </a></div></div> <footer data-v-22cb8fd0><span data-v-22cb8fd0>Built with</span> <a href="https://nuxtjs.org" target="_blank" data-v-22cb8fd0><svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" class="nuxt-icon" data-v-22cb8fd0 data-v-22cb8fd0><path d="M13.5599 8.54348L12.8055 9.87164L10.2257 5.3282L2.306 19.274H7.66815C7.66815 20.0075 8.25298 20.6021 8.97441 20.6021H2.306C1.83937 20.6021 1.40822 20.3489 1.17494 19.9379C0.941664 19.527 0.941687 19.0208 1.175 18.6099L9.09469 4.66412C9.32802 4.25316 9.75926 4 10.226 4C10.6926 4 11.1239 4.25316 11.3572 4.66412L13.5599 8.54348V8.54348Z" fill="#00C58E" data-v-22cb8fd0 data-v-22cb8fd0></path><path d="M19.2769 18.6099L14.3143 9.87165L13.5599 8.54348L12.8055 9.87165L7.84343 18.6099C7.61011 19.0208 7.61009 19.527 7.84337 19.9379C8.07665 20.3489 8.50779 20.6021 8.97443 20.6021H18.1443C18.611 20.6021 19.0424 20.3491 19.2758 19.9382C19.5092 19.5272 19.5092 19.0209 19.2758 18.6099H19.2769ZM8.97443 19.274L13.5599 11.1998L18.1443 19.274H8.97443H8.97443Z" fill="#2F495E" data-v-22cb8fd0 data-v-22cb8fd0></path><path d="M22.825 19.938C22.5917 20.3489 22.1606 20.6021 21.694 20.6021H18.1443C18.8657 20.6021 19.4505 20.0075 19.4505 19.274H21.6913L15.3331 8.07696L14.3142 9.87164L13.5599 8.54348L14.2021 7.41287C14.4354 7.00192 14.8667 6.74875 15.3334 6.74875C15.8001 6.74875 16.2313 7.00192 16.4646 7.41287L22.825 18.6099C23.0583 19.0208 23.0583 19.5271 22.825 19.938V19.938Z" fill="#108775" data-v-22cb8fd0 data-v-22cb8fd0></path></svg></a> <span data-v-22cb8fd0>&</span> <a href="https://docs.dev.to/api" rel="nofollow noopener" target="_blank" data-v-22cb8fd0><svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" data-v-22cb8fd0 data-v-22cb8fd0><path d="M1.5726 5.13748C1.42945 5.20622 1.2411 5.36661 1.15822 5.48117C1 5.69503 1 5.74849 1 11.8739C1 17.9993 1 18.0528 1.15822 18.2667C1.2411 18.3812 1.42945 18.5416 1.5726 18.6104C1.8137 18.7402 2.46164 18.7478 12 18.7478C21.5384 18.7478 22.1863 18.7402 22.4274 18.6104C22.5706 18.5416 22.7589 18.3812 22.8418 18.2667C23 18.0528 23 17.9993 23 11.8739C23 5.74849 23 5.69503 22.8418 5.48117C22.7589 5.36661 22.5706 5.20622 22.4274 5.13748C22.1863 5.00764 21.5384 5 12 5C2.46164 5 1.8137 5.00764 1.5726 5.13748ZM7.7055 8.2613C8.0822 8.45989 8.59454 9.0098 8.77536 9.40694C8.89589 9.66664 8.91095 9.94922 8.91095 12.0649C8.91095 14.3104 8.90344 14.4478 8.75275 14.7839C8.51919 15.288 8.16506 15.6546 7.68288 15.899C7.26096 16.1052 7.22328 16.1128 5.7315 16.1358L4.20206 16.1663V12.1031V8.04744L5.80684 8.07035C7.27602 8.09327 7.42672 8.10854 7.7055 8.2613ZM13.6952 8.89521V9.73538H12.4521H11.2089V10.4991V11.2629H11.9623H12.7158V12.1031V12.9432H11.9623H11.2089V13.707V14.4708H12.4521H13.6952V15.3109V16.151H12C10.1315 16.151 10.0411 16.1358 9.67191 15.6928L9.47603 15.4484V12.1336C9.47603 8.46752 9.46851 8.49807 9.95069 8.20783C10.1692 8.07035 10.3425 8.05508 11.9473 8.05508H13.6952V8.89521ZM16.5658 10.3769C16.8897 11.6295 17.1685 12.6912 17.176 12.7293C17.1911 12.7675 17.4699 11.7441 17.8014 10.461C18.1254 9.17017 18.4343 8.1009 18.4795 8.08563C18.5247 8.06271 18.9541 8.06271 19.4288 8.07035L20.3028 8.09327L19.376 11.6219C18.8713 13.5542 18.4117 15.2269 18.3664 15.3261C18.0123 16.0135 17.274 16.3343 16.7164 16.0441C16.4528 15.899 16.0911 15.4865 15.9705 15.1887C15.9254 15.0665 15.4884 13.4549 15.0062 11.6142C14.524 9.76593 14.1171 8.20783 14.0945 8.15437C14.0644 8.07035 14.2301 8.05508 15.0212 8.07035L15.9856 8.09327L16.5658 10.3769Z" fill="black" data-v-22cb8fd0 data-v-22cb8fd0></path><path d="M5.93491 12.103V14.4707H6.27394C6.66574 14.4707 7.01983 14.3103 7.1404 14.0965C7.18559 14.0048 7.21575 13.2105 7.21575 12.0648V10.1783L6.99725 9.95683C6.80133 9.76591 6.71847 9.73535 6.35683 9.73535H5.93491V12.103Z" fill="black" data-v-22cb8fd0 data-v-22cb8fd0></path></svg></a></footer></div></div></div><script>window.__NUXT__=function(e,t,a,n,o){return t.type_of="article",t.id=1050220,t.title="Introducing VoiceCue - Find sentiments, tags, entities, actions like a DJ üßô‚ú®",t.description="My submission to the Deepgram Hackathon on DEV!",t.readable_publish_date="Apr 10",t.slug="introducing-voicecue-find-sentiments-tags-entities-actions-like-a-dj-4kjk",t.path="/madza/introducing-voicecue-find-sentiments-tags-entities-actions-like-a-dj-4kjk",t.url=a,t.comments_count=8,t.public_reactions_count=57,t.collection_id=e,t.published_timestamp=n,t.positive_reactions_count=57,t.cover_image="https://res.cloudinary.com/practicaldev/image/fetch/s--mQnE4mM0--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/h6ldp523x7e65wu4t6r6.png",t.social_image="https://res.cloudinary.com/practicaldev/image/fetch/s--grmQMt-f--/c_imagga_scale,f_auto,fl_progressive,h_500,q_auto,w_1000/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/h6ldp523x7e65wu4t6r6.png",t.canonical_url=a,t.created_at="2022-04-09T21:54:07Z",t.edited_at="2022-04-11T20:14:23Z",t.crossposted_at=e,t.published_at=n,t.last_comment_at="2022-04-12T01:46:37Z",t.reading_time_minutes=7,t.tag_list="hackwithdg, deepgram, deeplearning, ai",t.tags=["hackwithdg","deepgram","deeplearning","ai"],t.body_html='<h3>\n  <a name="overview-of-my-submission" href="#overview-of-my-submission">\n  </a>\n  Overview of My Submission\n</h3>\n\n<p>Many of us have come across the tidy task of voice recording analysis, where you had to listen to the whole audio to identify the most essential parts.</p>\n\n<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--5oDaNQit--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/7gxdx8eq4ocwhe6fd8g2.jpeg" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--5oDaNQit--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/7gxdx8eq4ocwhe6fd8g2.jpeg" alt="Problem" loading="lazy" width="880" height="380"></a></p>\n\n<p>Manual processing can be very time-inefficient. Just listening from end to end would often not be enough. You would have to double or even triple that time since you would have to pause and replay some parts of the audio.</p>\n\n<p>During the mid-March to mid-April, I came up with <a href="https://cue.madza.dev">VoiceCue</a>, an app that generates cue timecodes that lets you find all the important parts of your voice recordings like sentiments, entities, and tags with just a click.</p>\n\n<p>In this article, we will review it.</p>\n\n<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--0ynolo2s--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/n4qxutv8g1ks063dvahn.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--0ynolo2s--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/n4qxutv8g1ks063dvahn.png" alt="Preview" loading="lazy" width="880" height="426"></a></p>\n\n<p>This project was built specifically as an entry for the <a href="https://dev.com">DEV</a> and <a href="https://deepgram.com">Deepgram</a> hackathon. It was an awesome experience since the participation motivated me and I came up with a product that could hopefully benefit others as well.</p>\n\n<h3>\n  <a name="submission-category" href="#submission-category">\n  </a>\n  Submission Category\n</h3>\n\n<p>The root idea of the application comes from the world famous DJs in the music industry. Before the gigs they set cues for the audio tracks that they will play, marking the breakdown, drop, outro and so on. This way they can find specific parts quickly if they need to.</p>\n\n<p>Thanks to <a href="https://developers.deepgram.com/api-reference/">Deepgram API</a> I was able to implement my own cue system and pair it with the analysis of voice recordings. The cues are being generated for positive and negative sentiments, frequently used words, numerous entities, and actions as well as custom search queries.</p>\n\n<p>I\'ve never seen an AI-based cue tool for voice recordings, so I thought the perfect category for this would be <strong>Wacky Wildcards</strong>.</p>\n\n<h3>\n  <a name="link-to-code-githubcommadzadevvoicecue" href="#link-to-code-githubcommadzadevvoicecue">\n  </a>\n  Link to Code: <a href="https://github.com/madzadev/voice-cue">github.com/madzadev/voice-cue</a> üßë‚Äçüíª\n</h3>\n\n<h3>\n  <a name="deployed-app-cuemadzadev" href="#deployed-app-cuemadzadev">\n  </a>\n  Deployed app: <a href="https://cue.madza.dev">cue.madza.dev</a> üéâ\n</h3>\n\n\n<hr>\n\n<h3>\n  <a name="how-does-it-work" href="#how-does-it-work">\n  </a>\n  How does it work?\n</h3>\n\n<p>An audio cue is basically a shortcut that lets you jump to a predefined position in the audio.</p>\n\n<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--OyUFqKcZ--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/32ztu18a7jasb9iyts49.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--OyUFqKcZ--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/32ztu18a7jasb9iyts49.png" alt="Waveform" loading="lazy" width="880" height="118"></a></p>\n\n<p>The app workflow is as simple as uploading your voice recording, selecting which type of analysis to perform, and clicking on the generated cues in the list to instantly navigate to its exact position in the voice recording. </p>\n\n<h3>\n  <a name="overview-and-stats" href="#overview-and-stats">\n  </a>\n  Overview and stats\n</h3>\n\n<p>Overview statistics gives an overall summary of the recording.</p>\n\n<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--xbDCC8oG--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/639ydh7mn9py3xkqz98s.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--xbDCC8oG--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/639ydh7mn9py3xkqz98s.png" alt="Statistics" loading="lazy" width="810" height="291"></a></p>\n\n<p>The analysis include: total characters, sentences and words, total identified sentiment cues and their cumulative tone score, as well as total identified tags, named entities, actions and speakers count in the voice recording.</p>\n\n<h3>\n  <a name="interactive-transcript" href="#interactive-transcript">\n  </a>\n  Interactive transcript\n</h3>\n\n<p>The generated transcript is interactive, highlighting the words as they are heard in the voice recording. This feature makes it easier to track the current position in the overall context as well as increases accessibility for people with hearing problems.</p>\n\n<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--6NPvNHwx--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/ku3oijoi0h5d16p7y94g.gif" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--6NPvNHwx--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/ku3oijoi0h5d16p7y94g.gif" alt="Interactive transcript" loading="lazy" width="880" height="425" data-animated="true"></a></p>\n\n<p>Furthermore, user can click on any word on the transcript and the audio progress will be automatically set to the position of the word in the voice recording.</p>\n\n<p>The audio waveform lets user visually perceive the dynamics of the voice and identify silences. For playback, the user can switch between audio controls and manually adjusting the progress marker on the waveform.</p>\n\n<h3>\n  <a name="sentiment-analysis" href="#sentiment-analysis">\n  </a>\n  Sentiment analysis\n</h3>\n\n<p>Sentiment analysis checks against the words with positive and negative meanings.</p>\n\n<p>After selecting the sentiment, the list of sentiment words is returned. The header shows the selected sentiment and how many words of that sentiment appeared in the voice recording.</p>\n\n<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--NPjri7FJ--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/pt2m8ybs9m64smjcvxxf.gif" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--NPjri7FJ--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/pt2m8ybs9m64smjcvxxf.gif" alt="Sentiment analysis" loading="lazy" width="880" height="425" data-animated="true"></a></p>\n\n<p>Each individual tag in the list displays the word, timecode, and its sentiment rank on the scale from -4 for the negative to +4 for the positive words.</p>\n\n<p>There are various practical use cases for both. For example, the user might check the positive sentiment to compile a list of referrals for personal website. Or he/she might check the negative sentiment to get some feedback on what to improve on it.</p>\n\n<h3>\n  <a name="tag-cloud" href="#tag-cloud">\n  </a>\n  Tag cloud\n</h3>\n\n<p>The tag cloud returns the most used words in the voice recording. </p>\n\n<p>The higher the number of occurrences in the recording, the bigger the font size for the tag is used in the cloud. Also, a different color scheme is used for each tag so it is easier to distinguish.</p>\n\n<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--le5XTdFt--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/u6x00uw3uq2y2pjvtau2.gif" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--le5XTdFt--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/u6x00uw3uq2y2pjvtau2.gif" alt="Tag cloud" loading="lazy" width="880" height="425" data-animated="true"></a></p>\n\n<p>After a tag is selected the list header shows how many times the tag occurred throughout the recording. For individual cues, the sequence of appearance is shown along with the time code.</p>\n\n<p>By looking at the word cloud it is easy to understand what were the main topics of the conversation. This could be very useful if someone wants to see what products or services are mentioned the most, for example.</p>\n\n<h3>\n  <a name="named-entities" href="#named-entities">\n  </a>\n  Named entities\n</h3>\n\n<p>Named entity analysis lets you find cues based on word categorization. </p>\n\n<p>Currently supported named entities are Person, Place, Organization, Money, Unit, and Date.</p>\n\n<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--OP6JbJH1--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/2abgsz5bjr94mecs8uwx.gif" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--OP6JbJH1--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/2abgsz5bjr94mecs8uwx.gif" alt="Named entities" loading="lazy" width="880" height="425" data-animated="true"></a></p>\n\n<p>When a named entity is selected, the number of total occurrences on the recording is displayed in the header. Each individual generated cue represents the specific word of the entity, its sequence of appearance as well as the timecode.</p>\n\n<p>Named entities can be very useful. For example, a company would check for a Person entity to quickly generate timecodes for the mentions of board members in the recording. Or search for Money entity to quickly jump to where the company budget is mentioned.</p>\n\n<h3>\n  <a name="actions" href="#actions">\n  </a>\n  Actions\n</h3>\n\n<p>Actions analysis returns the verbs, by categorizing them into past, present, and future. Currently supported categories are PastTense, Infinitive, Copula, Modal, and Gerund.</p>\n\n<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--Wf1CybA5--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/4yket479qjp6zkt52g1e.gif" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--Wf1CybA5--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/4yket479qjp6zkt52g1e.gif" alt="Actions" loading="lazy" width="880" height="425" data-animated="true"></a></p>\n\n<p>Similar to named entities, once the action is selected, it is displayed on the list header with the number of total occurrences on the recording. Each individual generated cue represents the specific word of the action, its sequence of appearance as well as the time code.</p>\n\n<p>Thanks to the categorization by the tense, action cues can be practically used if someone wants to find information about topics such as accomplished milestones, current processes, or planned tasks for the future.</p>\n\n<h3>\n  <a name="custom-search" href="#custom-search">\n  </a>\n  Custom search\n</h3>\n\n<p>If you were not able to find the cue you were looking for via any of the previous analysis methods, there is a custom search that let you search for custom words as well.</p>\n\n<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--RFWlcWQ3--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/91vzlju8ngvszi3n800i.gif" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--RFWlcWQ3--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/91vzlju8ngvszi3n800i.gif" alt="Custom search" loading="lazy" width="880" height="425" data-animated="true"></a></p>\n\n<p>The user is required to enter at least 3 characters to generate the list of cues. If the search query returns multiple cues, all are displayed below each other, with the word that includes the query, its sequence number, and timecode. </p>\n\n<h3>\n  <a name="responsiveness" href="#responsiveness">\n  </a>\n  Responsiveness\n</h3>\n\n<p>In our daily lives, we usually use phones to interview someone or record a meeting or event. Therefore making the app fully responsive to different screen widths was among the main priorities. </p>\n\n<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--nla7bPea--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/s4rdk6sig5ksikovwpuc.gif" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--nla7bPea--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/s4rdk6sig5ksikovwpuc.gif" alt="Mobile screen" loading="lazy" width="880" height="514" data-animated="true"></a></p>\n\n<p>Since all the features are supported on smaller screens as well, the application is ready to be used in every situation, anytime you have a device with you.</p>\n\n<h3>\n  <a name="features-list" href="#features-list">\n  </a>\n  Features list:\n</h3>\n\n<ol>\n<li><p>Voice recognition - based on the <a href="https://developers.deepgram.com/">Deepgram API</a></p></li>\n<li><p>General stats - an overview of voice recording</p></li>\n<li><p>Sentiment analysis - positive and negative word detection</p></li>\n<li><p>Word cloud generation - most used word classification</p></li>\n<li><p>Entity name recognition - categories such as person, place, etc</p></li>\n<li><p>Activity tracking - find actions in past, present, or future</p></li>\n<li><p>Interactive transcript - see progress or click to control it</p></li>\n<li><p>Speaker detection - total number of speakers in recording</p></li>\n<li><p>Cue word usage - short text samples for better context</p></li>\n<li><p>Custom search - extended ability to query for cues</p></li>\n<li><p>Waveform preview - see the dynamics of voice, identify silences</p></li>\n<li><p>Audio controls - play, pause, fast forward, and backward</p></li>\n<li><p>Drag and drop support - drop audio in the file select area</p></li>\n<li><p>Upload MP3 files - the most commonly used audio format</p></li>\n<li><p>Progress loaders  - improved UX for loading transcripts</p></li>\n<li><p>Fully responsive - works fine on mobile and tablets</p></li>\n<li><p>Colorful UI - for easier interaction and word highlighting</p></li>\n</ol>\n\n<h3>\n  <a name="tech-stack" href="#tech-stack">\n  </a>\n  Tech stack\n</h3>\n\n<p><a href="https://nextjs.org">NextJS</a> - React application framework</p>\n\n<p><a href="https://deepgram.com">Deepgram</a> - for AI-based speech recognition</p>\n\n<p><a href="https://www.npmjs.com/package/compromise">compromise</a>, <a href="https://www.npmjs.com/package/sentiment">sentiment</a> - for text processing</p>\n\n<p><a href="https://www.npmjs.com/package/react-tagcloud">react-tagcloud</a> - to generate word cloud</p>\n\n<p><a href="https://www.npmjs.com/package/react-tabs">react-tabs</a> - for navigation panels</p>\n\n<p><a href="https://www.npmjs.com/package/react-drag-drop-files">react-drag-drop-files</a> - for drag and drop support</p>\n\n<p><a href="https://www.npmjs.com/package/wavesurfer.js">wavesurfer.js</a> - to generate the audio waveform</p>\n\n<p><a href="https://github.com">GitHub</a> - to host the code</p>\n\n<p><a href="https://vercel.com">Vercel</a> - to deploy the project</p>\n\n<p><a href="https://eslint.org/">ESLint</a>, <a href="https://prettier.io/">prettier</a> - for linting and code formatting</p>\n\n<p><a href="https://namecheap.com">Namecheap</a> - for custom subdomain</p>\n\n<h3>\n  <a name="conclusion" href="#conclusion">\n  </a>\n  Conclusion\n</h3>\n\n<p>I want to thank <a href="https://www.forem.com/">Forem</a> for providing a great platform to learn, share findings, and engage with awesome people. Visiting <a href="https://dev.to">DEV</a> daily has become a habit of mine for years and I have already published 300+ posts.</p>\n\n<p>It was my pleasure to discover <a href="https://deepgram.com">Deepgram</a>, a co-host for this hackathon providing their API to build awesome stuff with. From now on I will have a valuable tool in my pocket that I will already know how to use when I will have to deal with speech recognition projects. </p>\n\n<p>The voice is an instrument of communication, lots of valuable information is being transferred with it every second. The powerful API of <a href="https://deepgram.com">Deepgram</a> is a wide step toward working smart, not hard, which will become an even more crucial skill to beat the competition in the future.</p>\n\n\n<hr>\n\n<p>Building projects have always been my passion and it gives me pleasure to help and inspire people. If you have any questions, feel free to reach out!</p>\n\n<p>Connect me on <a href="https://twitter.com/madzadev">Twitter</a>, <a href="https://www.linkedin.com/in/madzadev/">LinkedIn</a> and <a href="https://github.com/madzadev">GitHub</a>!</p>\n\n<p>Visit my <a href="https://madza.dev/code">Portfolio</a> for more projects like this.</p>\n\n',t.body_markdown="---\ntitle: Introducing VoiceCue - Find sentiments, tags, entities, actions like a DJ üßô‚ú®\npublished: true\ndescription: My submission to the Deepgram Hackathon on DEV!\ntags: hackwithdg, deepgram, deeplearning, ai\ncover_image: https://dev-to-uploads.s3.amazonaws.com/uploads/articles/h6ldp523x7e65wu4t6r6.png\n---\n\n### Overview of My Submission\n\nMany of us have come across the tidy task of voice recording analysis, where you had to listen to the whole audio to identify the most essential parts.\n\n![Problem](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/7gxdx8eq4ocwhe6fd8g2.jpeg)\n\nManual processing can be very time-inefficient. Just listening from end to end would often not be enough. You would have to double or even triple that time since you would have to pause and replay some parts of the audio.\n\nDuring the mid-March to mid-April, I came up with [VoiceCue](https://cue.madza.dev), an app that generates cue timecodes that lets you find all the important parts of your voice recordings like sentiments, entities, and tags with just a click.\n\nIn this article, we will review it.\n\n![Preview](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/n4qxutv8g1ks063dvahn.png)\n\nThis project was built specifically as an entry for the [DEV](https://dev.com) and [Deepgram](https://deepgram.com) hackathon. It was an awesome experience since the participation motivated me and I came up with a product that could hopefully benefit others as well.\n\n### Submission Category\n\nThe root idea of the application comes from the world famous DJs in the music industry. Before the gigs they set cues for the audio tracks that they will play, marking the breakdown, drop, outro and so on. This way they can find specific parts quickly if they need to.\n\nThanks to [Deepgram API](https://developers.deepgram.com/api-reference/) I was able to implement my own cue system and pair it with the analysis of voice recordings. The cues are being generated for positive and negative sentiments, frequently used words, numerous entities, and actions as well as custom search queries.\n\nI've never seen an AI-based cue tool for voice recordings, so I thought the perfect category for this would be **Wacky Wildcards**.\n\n### Link to Code: [github.com/madzadev/voice-cue](https://github.com/madzadev/voice-cue) üßë‚Äçüíª\n\n### Deployed app: [cue.madza.dev](https://cue.madza.dev) üéâ\n\n<hr/>\n\n### How does it work?\n\nAn audio cue is basically a shortcut that lets you jump to a predefined position in the audio.\n\n![Waveform](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/32ztu18a7jasb9iyts49.png)\n\nThe app workflow is as simple as uploading your voice recording, selecting which type of analysis to perform, and clicking on the generated cues in the list to instantly navigate to its exact position in the voice recording. \n\n### Overview and stats\n\nOverview statistics gives an overall summary of the recording.\n\n![Statistics](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/639ydh7mn9py3xkqz98s.png)\n\nThe analysis include: total characters, sentences and words, total identified sentiment cues and their cumulative tone score, as well as total identified tags, named entities, actions and speakers count in the voice recording.\n\n### Interactive transcript\n\nThe generated transcript is interactive, highlighting the words as they are heard in the voice recording. This feature makes it easier to track the current position in the overall context as well as increases accessibility for people with hearing problems.\n\n![Interactive transcript](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/ku3oijoi0h5d16p7y94g.gif)\n\nFurthermore, user can click on any word on the transcript and the audio progress will be automatically set to the position of the word in the voice recording.\n\nThe audio waveform lets user visually perceive the dynamics of the voice and identify silences. For playback, the user can switch between audio controls and manually adjusting the progress marker on the waveform.\n\n### Sentiment analysis\n\nSentiment analysis checks against the words with positive and negative meanings.\n\nAfter selecting the sentiment, the list of sentiment words is returned. The header shows the selected sentiment and how many words of that sentiment appeared in the voice recording.\n\n![Sentiment analysis](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/pt2m8ybs9m64smjcvxxf.gif)\n\nEach individual tag in the list displays the word, timecode, and its sentiment rank on the scale from -4 for the negative to +4 for the positive words.\n\nThere are various practical use cases for both. For example, the user might check the positive sentiment to compile a list of referrals for personal website. Or he/she might check the negative sentiment to get some feedback on what to improve on it.\n\n### Tag cloud\n\nThe tag cloud returns the most used words in the voice recording. \n\nThe higher the number of occurrences in the recording, the bigger the font size for the tag is used in the cloud. Also, a different color scheme is used for each tag so it is easier to distinguish.\n\n![Tag cloud](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/u6x00uw3uq2y2pjvtau2.gif)\n\nAfter a tag is selected the list header shows how many times the tag occurred throughout the recording. For individual cues, the sequence of appearance is shown along with the time code.\n\nBy looking at the word cloud it is easy to understand what were the main topics of the conversation. This could be very useful if someone wants to see what products or services are mentioned the most, for example.\n\n### Named entities\n\nNamed entity analysis lets you find cues based on word categorization. \n\nCurrently supported named entities are Person, Place, Organization, Money, Unit, and Date.\n\n![Named entities](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/2abgsz5bjr94mecs8uwx.gif)\n\nWhen a named entity is selected, the number of total occurrences on the recording is displayed in the header. Each individual generated cue represents the specific word of the entity, its sequence of appearance as well as the timecode.\n\nNamed entities can be very useful. For example, a company would check for a Person entity to quickly generate timecodes for the mentions of board members in the recording. Or search for Money entity to quickly jump to where the company budget is mentioned.\n\n### Actions\n\nActions analysis returns the verbs, by categorizing them into past, present, and future. Currently supported categories are PastTense, Infinitive, Copula, Modal, and Gerund.\n\n![Actions](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/4yket479qjp6zkt52g1e.gif)\n\nSimilar to named entities, once the action is selected, it is displayed on the list header with the number of total occurrences on the recording. Each individual generated cue represents the specific word of the action, its sequence of appearance as well as the time code.\n\nThanks to the categorization by the tense, action cues can be practically used if someone wants to find information about topics such as accomplished milestones, current processes, or planned tasks for the future.\n\n### Custom search\n\nIf you were not able to find the cue you were looking for via any of the previous analysis methods, there is a custom search that let you search for custom words as well.\n\n![Custom search](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/91vzlju8ngvszi3n800i.gif)\n\nThe user is required to enter at least 3 characters to generate the list of cues. If the search query returns multiple cues, all are displayed below each other, with the word that includes the query, its sequence number, and timecode. \n\n### Responsiveness\n\nIn our daily lives, we usually use phones to interview someone or record a meeting or event. Therefore making the app fully responsive to different screen widths was among the main priorities. \n\n![Mobile screen](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/s4rdk6sig5ksikovwpuc.gif)\n\nSince all the features are supported on smaller screens as well, the application is ready to be used in every situation, anytime you have a device with you.\n\n### Features list:\n\n1. Voice recognition - based on the [Deepgram API](https://developers.deepgram.com/)\n\n2. General stats - an overview of voice recording\n\n3. Sentiment analysis - positive and negative word detection\n\n4. Word cloud generation - most used word classification\n\n5. Entity name recognition - categories such as person, place, etc\n\n6. Activity tracking - find actions in past, present, or future\n\n7. Interactive transcript - see progress or click to control it\n\n8. Speaker detection - total number of speakers in recording\n\n9. Cue word usage - short text samples for better context\n\n10. Custom search - extended ability to query for cues\n\n11. Waveform preview - see the dynamics of voice, identify silences\n\n12. Audio controls - play, pause, fast forward, and backward\n\n13. Drag and drop support - drop audio in the file select area\n\n14. Upload MP3 files - the most commonly used audio format\n\n15. Progress loaders  - improved UX for loading transcripts\n\n16. Fully responsive - works fine on mobile and tablets\n\n17. Colorful UI - for easier interaction and word highlighting\n\n### Tech stack\n\n[NextJS](https://nextjs.org) - React application framework\n\n[Deepgram](https://deepgram.com) - for AI-based speech recognition\n\n[compromise](https://www.npmjs.com/package/compromise), [sentiment](https://www.npmjs.com/package/sentiment) - for text processing\n\n[react-tagcloud](https://www.npmjs.com/package/react-tagcloud) - to generate word cloud\n\n[react-tabs](https://www.npmjs.com/package/react-tabs) - for navigation panels\n\n[react-drag-drop-files](https://www.npmjs.com/package/react-drag-drop-files) - for drag and drop support\n\n[wavesurfer.js](https://www.npmjs.com/package/wavesurfer.js) - to generate the audio waveform\n\n[GitHub](https://github.com) - to host the code\n\n[Vercel](https://vercel.com) - to deploy the project\n\n[ESLint](https://eslint.org/), [prettier](https://prettier.io/) - for linting and code formatting\n\n[Namecheap](https://namecheap.com) - for custom subdomain\n\n### Conclusion\n\nI want to thank [Forem](https://www.forem.com/) for providing a great platform to learn, share findings, and engage with awesome people. Visiting [DEV](https://dev.to) daily has become a habit of mine for years and I have already published 300+ posts.\n\nIt was my pleasure to discover [Deepgram](https://deepgram.com), a co-host for this hackathon providing their API to build awesome stuff with. From now on I will have a valuable tool in my pocket that I will already know how to use when I will have to deal with speech recognition projects. \n\nThe voice is an instrument of communication, lots of valuable information is being transferred with it every second. The powerful API of [Deepgram](https://deepgram.com) is a wide step toward working smart, not hard, which will become an even more crucial skill to beat the competition in the future.\n\n<hr>\n\nBuilding projects have always been my passion and it gives me pleasure to help and inspire people. If you have any questions, feel free to reach out!\n\nConnect me on [Twitter](https://twitter.com/madzadev), [LinkedIn](https://www.linkedin.com/in/madzadev/) and [GitHub](https://github.com/madzadev)!\n\nVisit my [Portfolio](https://madza.dev/code) for more projects like this.",t.user={name:"Madza",username:"madza",twitter_username:o,github_username:o,website_url:"https://madza.dev/",profile_image:"https://res.cloudinary.com/practicaldev/image/fetch/s--5uEZ1zA8--/c_fill,f_auto,fl_progressive,h_640,q_auto,w_640/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/159737/10b8de99-9383-42da-80e2-851af40d5d0f.png",profile_image_90:"https://res.cloudinary.com/practicaldev/image/fetch/s--4L_SFF-C--/c_fill,f_auto,fl_progressive,h_90,q_auto,w_90/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/159737/10b8de99-9383-42da-80e2-851af40d5d0f.png"},{layout:"default",data:[{}],fetch:{"data-v-70afb46a:0":{article:t}},error:e,state:{currentArticle:t},serverRendered:!0,routePath:"/madza/1050220",config:{_app:{basePath:"/nuxtstop/",assetsPath:"/nuxtstop/_nuxt/",cdnURL:e}}}}(null,{},"https://dev.to/madza/introducing-voicecue-find-sentiments-tags-entities-actions-like-a-dj-4kjk","2022-04-10T16:40:12Z","madzadev")</script><script src="/nuxtstop/_nuxt/f6e87fb.js" defer></script><script src="/nuxtstop/_nuxt/dc9ce94.js" defer></script><script src="/nuxtstop/_nuxt/6474719.js" defer></script><script src="/nuxtstop/_nuxt/9b75090.js" defer></script><script src="/nuxtstop/_nuxt/18df600.js" defer></script>
  </body>
</html>
